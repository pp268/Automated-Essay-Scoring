{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import language_check\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training_set_rel3.tsv',sep='\\t',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 28 columns):\n",
      "essay_id          12976 non-null int64\n",
      "essay_set         12976 non-null int64\n",
      "essay             12976 non-null object\n",
      "rater1_domain1    12976 non-null int64\n",
      "rater2_domain1    12976 non-null int64\n",
      "rater3_domain1    128 non-null float64\n",
      "domain1_score     12976 non-null int64\n",
      "rater1_domain2    1800 non-null float64\n",
      "rater2_domain2    1800 non-null float64\n",
      "domain2_score     1800 non-null float64\n",
      "rater1_trait1     2292 non-null float64\n",
      "rater1_trait2     2292 non-null float64\n",
      "rater1_trait3     2292 non-null float64\n",
      "rater1_trait4     2292 non-null float64\n",
      "rater1_trait5     723 non-null float64\n",
      "rater1_trait6     723 non-null float64\n",
      "rater2_trait1     2292 non-null float64\n",
      "rater2_trait2     2292 non-null float64\n",
      "rater2_trait3     2292 non-null float64\n",
      "rater2_trait4     2292 non-null float64\n",
      "rater2_trait5     723 non-null float64\n",
      "rater2_trait6     723 non-null float64\n",
      "rater3_trait1     128 non-null float64\n",
      "rater3_trait2     128 non-null float64\n",
      "rater3_trait3     128 non-null float64\n",
      "rater3_trait4     128 non-null float64\n",
      "rater3_trait5     128 non-null float64\n",
      "rater3_trait6     128 non-null float64\n",
      "dtypes: float64(22), int64(5), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['essay_id','essay_set','essay','domain1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \n",
       "0              8  Dear local newspaper  I think effects computer...  \n",
       "1              9  Dear     I believe that using computers will b...  \n",
       "2              7  Dear        More and more people use computers...  \n",
       "3             10  Dear Local Newspaper    I have found that many...  \n",
       "4              8  Dear   I know having computers has a positive ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_char(essay):\n",
    "    return re.sub('@\\S+|[^A-Za-z0-9]',' ',essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_essay'] = df['essay'].apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(essay):\n",
    "    return len(nltk.word_tokenize(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] =df['clean_essay'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_count(essay):\n",
    "    return len(nltk.sent_tokenize(essay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent_count'] =df['essay'].apply(sent_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_spell(essay):\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    spell = SpellChecker()\n",
    "    words = essay.split()\n",
    "    misspelled = set()\n",
    "    err_count = 0\n",
    "    for word in words:\n",
    "        if d.check(word) == False:\n",
    "            misspelled.add(word)\n",
    "            err_count += 1\n",
    "    corr_dict = {}\n",
    "    for word in misspelled:\n",
    "        corr_dict[word] = spell.correction(word)\n",
    "    essay_df = pd.DataFrame(essay.split())\n",
    "    essay_df.replace(corr_dict,inplace=True)\n",
    "    essay = ' '.join(list(essay_df[0]))\n",
    "    return err_count,essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['spell_err'],df['corrected_essay'] = zip(*df['clean_essay'].map(check_spell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('corr_essay',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv('corr_essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_error</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>0.468023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>0.450363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>0.514493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>0.459016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>0.411514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  essay_id  essay_set  \\\n",
       "0           0         1          1   \n",
       "1           1         2          1   \n",
       "2           2         3          1   \n",
       "3           3         4          1   \n",
       "4           4         5          1   \n",
       "\n",
       "                                               essay  domain1_score  \\\n",
       "0  Dear local newspaper, I think effects computer...              8   \n",
       "1  Dear @CAPS1 @CAPS2, I believe that using compu...              9   \n",
       "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...              7   \n",
       "3  Dear Local Newspaper, @CAPS1 I have found that...             10   \n",
       "4  Dear @LOCATION1, I know having computers has a...              8   \n",
       "\n",
       "                                         clean_essay  word_count  sent_count  \\\n",
       "0  Dear local newspaper  I think effects computer...         344          16   \n",
       "1  Dear     I believe that using computers will b...         413          20   \n",
       "2  Dear        More and more people use computers...         276          14   \n",
       "3  Dear Local Newspaper    I have found that many...         488          27   \n",
       "4  Dear   I know having computers has a positive ...         469          30   \n",
       "\n",
       "   spell_error  spell_err1                                    corrected_essay  \\\n",
       "0           11          11  Dear local newspaper I think effects computers...   \n",
       "1           16          16  Dear I believe that using computers will benef...   \n",
       "2            2           2  Dear More and more people use computers but no...   \n",
       "3           24          24  Dear Local Newspaper I have found that many ex...   \n",
       "4           13          13  Dear I know having computers has a positive ef...   \n",
       "\n",
       "   unique_word_ratio  \n",
       "0           0.468023  \n",
       "1           0.450363  \n",
       "2           0.514493  \n",
       "3           0.459016  \n",
       "4           0.411514  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(essay):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    stop_words.remove('not')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    essay = essay.lower()\n",
    "    essay = nltk.word_tokenize(essay)\n",
    "    essay=[lemmatizer.lemmatize(word) for word in essay if not word in stop_words]\n",
    "    essay=' '.join(essay)\n",
    "    return essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['essay_documents'] = clean_df['corrected_essay'].apply(create_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_count(essay):\n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adv_count = 0\n",
    "    adj_count = 0\n",
    "    word_pos = nltk.pos_tag(essay.split())\n",
    "    for pos in word_pos:\n",
    "        if pos[1][0] == 'N':\n",
    "            noun_count += 1\n",
    "        elif pos[1][0] == 'V':\n",
    "            verb_count += 1\n",
    "        elif pos[1][0] == 'J':\n",
    "            adj_count += 1\n",
    "        elif pos[1][0] == 'R':\n",
    "            adv_count += 1\n",
    "    return noun_count, verb_count, adv_count, adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['noun_count'], clean_df['verb_count'], clean_df['adv_count'], clean_df['adj_count'] = zip(*clean_df['essay_documents'].map(pos_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_redability(essay):\n",
    "    return textstat.flesch_reading_ease(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['readability_score'] = clean_df['essay'].apply(compute_redability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_word_ratio(essay):\n",
    "    tokens = nltk.word_tokenize(essay.lower())\n",
    "    ratio = len(set(tokens))/len(tokens)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['unique_word_ratio'] = clean_df['essay_documents'].apply(unique_word_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_df',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = pd.read_csv(\"clean_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>dear people use computer not everyone agrees b...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "   word_count  sent_count  spell_err1  \\\n",
       "0         344          16          11   \n",
       "1         413          20          16   \n",
       "2         276          14           2   \n",
       "3         488          27          24   \n",
       "4         469          30          13   \n",
       "\n",
       "                                     corrected_essay  \\\n",
       "0  Dear local newspaper I think effects computers...   \n",
       "1  Dear I believe that using computers will benef...   \n",
       "2  Dear More and more people use computers but no...   \n",
       "3  Dear Local Newspaper I have found that many ex...   \n",
       "4  Dear I know having computers has a positive ef...   \n",
       "\n",
       "                                     essay_documents  noun_count  verb_count  \\\n",
       "0  dear local newspaper think effect computer peo...          78          37   \n",
       "1  dear believe using computer benefit u many way...         103          55   \n",
       "2  dear people use computer not everyone agrees b...          74          31   \n",
       "3  dear local newspaper found many expert say com...         134          53   \n",
       "4  dear know computer positive effect people comp...         117          40   \n",
       "\n",
       "   adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "0         15         28              74.02           0.618182  \n",
       "1         10         24              67.08           0.569444  \n",
       "2          4         18              68.20           0.646154  \n",
       "3         24         45              53.34           0.584559  \n",
       "4         11         27              72.66           0.531818  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_essay = clean_df[(clean_df['essay_set']== 1) | (clean_df['essay_set']== 2) | (clean_df['essay_set']== 7) | (clean_df['essay_set']== 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_essay.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>syn_overlap_prop</th>\n",
       "      <th>prompt_overlap</th>\n",
       "      <th>prompt_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>806</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>In most stories mothers and daughters are eith...</td>\n",
       "      <td>story mother daughter either enemy friend stor...</td>\n",
       "      <td>132</td>\n",
       "      <td>73</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>56.05</td>\n",
       "      <td>0.605479</td>\n",
       "      <td>52</td>\n",
       "      <td>0.142077</td>\n",
       "      <td>33</td>\n",
       "      <td>0.090164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>526</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>I never understood the meaning laughter is the...</td>\n",
       "      <td>never understood meaning laughter shortest dis...</td>\n",
       "      <td>93</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.516260</td>\n",
       "      <td>33</td>\n",
       "      <td>0.133603</td>\n",
       "      <td>25</td>\n",
       "      <td>0.101215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "      <td>When you laugh  is   out of habit  or is   cau...</td>\n",
       "      <td>777</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>When you laugh is out of habit or is cause Wha...</td>\n",
       "      <td>laugh habit cause cause laughing even thing ca...</td>\n",
       "      <td>137</td>\n",
       "      <td>88</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>60.79</td>\n",
       "      <td>0.723837</td>\n",
       "      <td>27</td>\n",
       "      <td>0.078261</td>\n",
       "      <td>20</td>\n",
       "      <td>0.057971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "      <td>Trippin  on fen...</td>\n",
       "      <td>555</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>tripping on fences I am years young and in tho...</td>\n",
       "      <td>tripping fence year young short year ever reme...</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>72.05</td>\n",
       "      <td>0.643777</td>\n",
       "      <td>26</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>21</td>\n",
       "      <td>0.089744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>460</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Many people believe that laughter can improve ...</td>\n",
       "      <td>many people believe laughter improve life laug...</td>\n",
       "      <td>80</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>72.05</td>\n",
       "      <td>0.665138</td>\n",
       "      <td>37</td>\n",
       "      <td>0.168950</td>\n",
       "      <td>25</td>\n",
       "      <td>0.114155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "5870     21626          8   In most stories mothers and daughters are eit...   \n",
       "5871     21628          8   I never understood the meaning laughter is th...   \n",
       "5872     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "5873     21630          8                                 Trippin' on fen...   \n",
       "5874     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "      domain1_score                                        clean_essay  \\\n",
       "5870             35   In most stories mothers and daughters are eit...   \n",
       "5871             32   I never understood the meaning laughter is th...   \n",
       "5872             40  When you laugh  is   out of habit  or is   cau...   \n",
       "5873             40                                 Trippin  on fen...   \n",
       "5874             40   Many people believe that laughter can improve...   \n",
       "\n",
       "      word_count  sent_count  spell_err1  \\\n",
       "5870         806          27           1   \n",
       "5871         526          35           5   \n",
       "5872         777          41           7   \n",
       "5873         555          39           3   \n",
       "5874         460          29           1   \n",
       "\n",
       "                                        corrected_essay  \\\n",
       "5870  In most stories mothers and daughters are eith...   \n",
       "5871  I never understood the meaning laughter is the...   \n",
       "5872  When you laugh is out of habit or is cause Wha...   \n",
       "5873  tripping on fences I am years young and in tho...   \n",
       "5874  Many people believe that laughter can improve ...   \n",
       "\n",
       "                                        essay_documents  noun_count  \\\n",
       "5870  story mother daughter either enemy friend stor...         132   \n",
       "5871  never understood meaning laughter shortest dis...          93   \n",
       "5872  laugh habit cause cause laughing even thing ca...         137   \n",
       "5873  tripping fence year young short year ever reme...          79   \n",
       "5874  many people believe laughter improve life laug...          80   \n",
       "\n",
       "      verb_count  adv_count  adj_count  readability_score  unique_word_ratio  \\\n",
       "5870          73         52         60              56.05           0.605479   \n",
       "5871          53         40         45              50.00           0.516260   \n",
       "5872          88         31         60              60.79           0.723837   \n",
       "5873          56         38         45              72.05           0.643777   \n",
       "5874          52         29         46              72.05           0.665138   \n",
       "\n",
       "      syn_overlap  syn_overlap_prop  prompt_overlap  prompt_overlap_prop  \n",
       "5870           52          0.142077              33             0.090164  \n",
       "5871           33          0.133603              25             0.101215  \n",
       "5872           27          0.078261              20             0.057971  \n",
       "5873           26          0.111111              21             0.089744  \n",
       "5874           37          0.168950              25             0.114155  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = open(\"Prompt1.txt\",'r',encoding='utf-8')\n",
    "prompt1 = prompt1.read()\n",
    "prompt2 = open(\"Prompt2.txt\",'r',encoding='utf-8')\n",
    "prompt2 = prompt2.read()\n",
    "prompt7 = open(\"Prompt7.txt\",'r',encoding='utf-8')\n",
    "prompt7 = prompt7.read()\n",
    "prompt8 = open(\"Prompt8.txt\",'r',encoding='utf-8')\n",
    "prompt8 = prompt8.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_set = [1,2,7,8]\n",
    "prompts = [prompt1,prompt2,prompt7,prompt8]\n",
    "essay_prompt_df = pd.DataFrame({'essay_set':persuasive_set,'prompt':prompts},index=persuasive_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_prompt_df['clean_prompt'] = essay_prompt_df['prompt'].apply(remove_special_char)\n",
    "essay_prompt_df['documents'] = essay_prompt_df['clean_prompt'].apply(create_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>prompt</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>More and more people use computers  but not ev...</td>\n",
       "      <td>people use computer not everyone agrees benefi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in the Libraries\\n\"All of us can th...</td>\n",
       "      <td>Censorship in the Libraries  All of us can thi...</td>\n",
       "      <td>censorship library u think book hope none chil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>Write about patience  Being patient means that...</td>\n",
       "      <td>write patience patient mean understanding tole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>We all understand the benefits of laughter. Fo...</td>\n",
       "      <td>We all understand the benefits of laughter  Fo...</td>\n",
       "      <td>understand benefit laughter example someone sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             prompt  \\\n",
       "1          1  More and more people use computers, but not ev...   \n",
       "2          2  Censorship in the Libraries\\n\"All of us can th...   \n",
       "7          7  Write about patience. Being patient means that...   \n",
       "8          8  We all understand the benefits of laughter. Fo...   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "1  More and more people use computers  but not ev...   \n",
       "2  Censorship in the Libraries  All of us can thi...   \n",
       "7  Write about patience  Being patient means that...   \n",
       "8  We all understand the benefits of laughter  Fo...   \n",
       "\n",
       "                                           documents  \n",
       "1  people use computer not everyone agrees benefi...  \n",
       "2  censorship library u think book hope none chil...  \n",
       "7  write patience patient mean understanding tole...  \n",
       "8  understand benefit laughter example someone sa...  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(prompt):\n",
    "    synonyms = set()\n",
    "    tokens = nltk.word_tokenize(prompt)\n",
    "    for word in tokens:\n",
    "        synset = nltk.wordnet.wordnet.synsets(word)\n",
    "        for ss in synset:\n",
    "            for swords in ss.lemma_names():\n",
    "                synonyms.add(swords.lower())\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_prompt_df['synonyms'] = essay_prompt_df['documents'].apply(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>prompt</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>documents</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>More and more people use computers  but not ev...</td>\n",
       "      <td>people use computer not everyone agrees benefi...</td>\n",
       "      <td>[spill_the_beans, proofreader, accompaniment, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in the Libraries All of us can thin...</td>\n",
       "      <td>Censorship in the Libraries All of us can thin...</td>\n",
       "      <td>censorship library u think book hope none chil...</td>\n",
       "      <td>[subroutine_library, shelf, rule, drive, run, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>Write about patience  Being patient means that...</td>\n",
       "      <td>write patience patient mean understanding tole...</td>\n",
       "      <td>[pursuit, chase, means, meter, mortal, unmatch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>We all understand the benefits of laughter. Fo...</td>\n",
       "      <td>We all understand the benefits of laughter  Fo...</td>\n",
       "      <td>understand benefit laughter example someone sa...</td>\n",
       "      <td>[mortal, unmatchable, severalise, partly, offi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             prompt  \\\n",
       "1          1  More and more people use computers, but not ev...   \n",
       "2          2  Censorship in the Libraries All of us can thin...   \n",
       "7          7  Write about patience. Being patient means that...   \n",
       "8          8  We all understand the benefits of laughter. Fo...   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "1  More and more people use computers  but not ev...   \n",
       "2  Censorship in the Libraries All of us can thin...   \n",
       "7  Write about patience  Being patient means that...   \n",
       "8  We all understand the benefits of laughter  Fo...   \n",
       "\n",
       "                                           documents  \\\n",
       "1  people use computer not everyone agrees benefi...   \n",
       "2  censorship library u think book hope none chil...   \n",
       "7  write patience patient mean understanding tole...   \n",
       "8  understand benefit laughter example someone sa...   \n",
       "\n",
       "                                            synonyms  \n",
       "1  [spill_the_beans, proofreader, accompaniment, ...  \n",
       "2  [subroutine_library, shelf, rule, drive, run, ...  \n",
       "7  [pursuit, chase, means, meter, mortal, unmatch...  \n",
       "8  [mortal, unmatchable, severalise, partly, offi...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_prompt_df.to_pickle('essay_prompt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_prompt_df = pd.read_pickle('essay_prompt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonyms_overlap = []\n",
    "synonyms_overlap_prop = []\n",
    "prompt_overlap = []\n",
    "prompt_overlap_prop = []\n",
    "\n",
    "for i in range(len(persuasive_essay)):    \n",
    "    essay_set = persuasive_essay['essay_set'][i]\n",
    "    essay_tokens = nltk.word_tokenize(persuasive_essay['essay_documents'][i])\n",
    "    prompt_tokens = nltk.word_tokenize(essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'documents'][essay_set])\n",
    "    synonyms = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "    synonyms_overlap_temp = [word for word in essay_tokens if word in synonyms]\n",
    "    prompt_overlap_temp = [word for word in essay_tokens if word in prompt_tokens]\n",
    "    \n",
    "    synonyms_overlap.append(len(synonyms_overlap_temp))\n",
    "    synonyms_overlap_prop.append(len(synonyms_overlap_temp)/(len(essay_tokens)+1))\n",
    "    prompt_overlap.append(len(prompt_overlap_temp))\n",
    "    prompt_overlap_prop.append(len(prompt_overlap_temp)/(len(essay_tokens)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "persuasive_essay['syn_overlap'] = synonyms_overlap\n",
    "persuasive_essay['syn_overlap_prop'] = synonyms_overlap_prop\n",
    "persuasive_essay['prompt_overlap'] = prompt_overlap\n",
    "persuasive_essay['prompt_overlap_prop'] = prompt_overlap_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>syn_overlap_prop</th>\n",
       "      <th>prompt_overlap</th>\n",
       "      <th>prompt_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>46</td>\n",
       "      <td>0.277108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>39</td>\n",
       "      <td>0.179724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>dear people use computer not everyone agrees b...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>62</td>\n",
       "      <td>0.473282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>0.311355</td>\n",
       "      <td>55</td>\n",
       "      <td>0.201465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>51</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "   word_count  sent_count  spell_err1  \\\n",
       "0         344          16          11   \n",
       "1         413          20          16   \n",
       "2         276          14           2   \n",
       "3         488          27          24   \n",
       "4         469          30          13   \n",
       "\n",
       "                                     corrected_essay  \\\n",
       "0  Dear local newspaper I think effects computers...   \n",
       "1  Dear I believe that using computers will benef...   \n",
       "2  Dear More and more people use computers but no...   \n",
       "3  Dear Local Newspaper I have found that many ex...   \n",
       "4  Dear I know having computers has a positive ef...   \n",
       "\n",
       "                                     essay_documents  noun_count  verb_count  \\\n",
       "0  dear local newspaper think effect computer peo...          78          37   \n",
       "1  dear believe using computer benefit u many way...         103          55   \n",
       "2  dear people use computer not everyone agrees b...          74          31   \n",
       "3  dear local newspaper found many expert say com...         134          53   \n",
       "4  dear know computer positive effect people comp...         117          40   \n",
       "\n",
       "   adv_count  adj_count  readability_score  unique_word_ratio  syn_overlap  \\\n",
       "0         15         28              74.02           0.618182           59   \n",
       "1         10         24              67.08           0.569444           56   \n",
       "2          4         18              68.20           0.646154           70   \n",
       "3         24         45              53.34           0.584559           85   \n",
       "4         11         27              72.66           0.531818           62   \n",
       "\n",
       "   syn_overlap_prop  prompt_overlap  prompt_overlap_prop  \n",
       "0          0.355422              46             0.277108  \n",
       "1          0.258065              39             0.179724  \n",
       "2          0.534351              62             0.473282  \n",
       "3          0.311355              55             0.201465  \n",
       "4          0.280543              51             0.230769  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_essay.to_csv('persuasive_essay',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "persuasive_essay = pd.read_csv('persuasive_essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>syn_overlap_prop</th>\n",
       "      <th>prompt_overlap</th>\n",
       "      <th>prompt_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>46</td>\n",
       "      <td>0.277108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>39</td>\n",
       "      <td>0.179724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>dear people use computer not everyone agrees b...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>62</td>\n",
       "      <td>0.473282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>0.311355</td>\n",
       "      <td>55</td>\n",
       "      <td>0.201465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>51</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "   word_count  sent_count  spell_err1  \\\n",
       "0         344          16          11   \n",
       "1         413          20          16   \n",
       "2         276          14           2   \n",
       "3         488          27          24   \n",
       "4         469          30          13   \n",
       "\n",
       "                                     corrected_essay  \\\n",
       "0  Dear local newspaper I think effects computers...   \n",
       "1  Dear I believe that using computers will benef...   \n",
       "2  Dear More and more people use computers but no...   \n",
       "3  Dear Local Newspaper I have found that many ex...   \n",
       "4  Dear I know having computers has a positive ef...   \n",
       "\n",
       "                                     essay_documents  noun_count  verb_count  \\\n",
       "0  dear local newspaper think effect computer peo...          78          37   \n",
       "1  dear believe using computer benefit u many way...         103          55   \n",
       "2  dear people use computer not everyone agrees b...          74          31   \n",
       "3  dear local newspaper found many expert say com...         134          53   \n",
       "4  dear know computer positive effect people comp...         117          40   \n",
       "\n",
       "   adv_count  adj_count  readability_score  unique_word_ratio  syn_overlap  \\\n",
       "0         15         28              74.02           0.618182           59   \n",
       "1         10         24              67.08           0.569444           56   \n",
       "2          4         18              68.20           0.646154           70   \n",
       "3         24         45              53.34           0.584559           85   \n",
       "4         11         27              72.66           0.531818           62   \n",
       "\n",
       "   syn_overlap_prop  prompt_overlap  prompt_overlap_prop  \n",
       "0          0.355422              46             0.277108  \n",
       "1          0.258065              39             0.179724  \n",
       "2          0.534351              62             0.473282  \n",
       "3          0.311355              55             0.201465  \n",
       "4          0.280543              51             0.230769  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_set1 = persuasive_essay[persuasive_essay['essay_set']==1]\n",
    "essay_set2 = persuasive_essay[persuasive_essay['essay_set']==2]\n",
    "essay_set7 = persuasive_essay[persuasive_essay['essay_set']==7]\n",
    "essay_set8 = persuasive_essay[persuasive_essay['essay_set']==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_set1.reset_index(inplace=True,drop=True)\n",
    "essay_set2.reset_index(inplace=True,drop=True)\n",
    "essay_set7.reset_index(inplace=True,drop=True)\n",
    "essay_set8.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_essay = clean_df[(clean_df['essay_set']== 3) | (clean_df['essay_set']== 4) | (clean_df['essay_set']== 5) | (clean_df['essay_set']== 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_essay.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>16629</td>\n",
       "      <td>6</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>one obstacle builder trying build building not...</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>77.27</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>16630</td>\n",
       "      <td>6</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>problem constructing docking dirigible natural...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>57.30</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>16631</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>3</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>builder empire state building faced obstacle a...</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>16632</td>\n",
       "      <td>6</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>2</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>obstacle builder empire state building could n...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>53.89</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>16633</td>\n",
       "      <td>6</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>2</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>want tell go attempt allow dirigible dock well...</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>64.78</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "7096     16629          6  The one obstacle the builders had when trying ...   \n",
       "7097     16630          6  Some of the problems with the constructing of ...   \n",
       "7098     16631          6  The builders of the Empire State building face...   \n",
       "7099     16632          6  The obstacles the builders of the Empire State...   \n",
       "7100     16633          6  You want me to tell you what they had to go th...   \n",
       "\n",
       "      domain1_score                                        clean_essay  \\\n",
       "7096              0  The one obstacle the builders had when trying ...   \n",
       "7097              2  Some of the problems with the constructing of ...   \n",
       "7098              3  The builders of the Empire State building face...   \n",
       "7099              2  The obstacles the builders of the Empire State...   \n",
       "7100              2  You want me to tell you what they had to go th...   \n",
       "\n",
       "      word_count  sent_count  spell_err1  \\\n",
       "7096         152           8          10   \n",
       "7097          66           3           0   \n",
       "7098         105           5           1   \n",
       "7099          68           2           1   \n",
       "7100         157           9           2   \n",
       "\n",
       "                                        corrected_essay  \\\n",
       "7096  The one obstacle the builders had when trying ...   \n",
       "7097  Some of the problems with the constructing of ...   \n",
       "7098  The builders of the Empire State building face...   \n",
       "7099  The obstacles the builders of the Empire State...   \n",
       "7100  You want me to tell you what they had to go th...   \n",
       "\n",
       "                                        essay_documents  noun_count  \\\n",
       "7096  one obstacle builder trying build building not...          36   \n",
       "7097  problem constructing docking dirigible natural...          13   \n",
       "7098  builder empire state building faced obstacle a...          30   \n",
       "7099  obstacle builder empire state building could n...          18   \n",
       "7100  want tell go attempt allow dirigible dock well...          33   \n",
       "\n",
       "      verb_count  adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "7096          13         10          9              77.27           0.706667  \n",
       "7097           8          4         11              57.30           0.925000  \n",
       "7098           8          5          9              58.62           0.814815  \n",
       "7099           7          3          5              53.89           0.810811  \n",
       "7100          19          4         14              64.78           0.632911  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "source3 = open(\"Source3.txt\",'r',encoding='utf-8')\n",
    "source3 = source3.read()\n",
    "source4 = open(\"Source4.txt\",'r',encoding='utf-8')\n",
    "source4 = source4.read()\n",
    "source5 = open(\"Source5.txt\",'r',encoding='utf-8')\n",
    "source5 = source5.read()\n",
    "source6 = open(\"Source6.txt\",'r',encoding='utf-8')\n",
    "source6 = source6.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_set = [3,4,5,6]\n",
    "source = [source3,source4,source5,source6]\n",
    "essay_source_df = pd.DataFrame({'essay_set':source_set,'source':source},index=source_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_source_df['clean_source'] = essay_source_df['source'].apply(remove_special_char)\n",
    "essay_source_df['documents'] = essay_source_df['clean_source'].apply(create_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_pos_tags(source):\n",
    "    word_pos = nltk.pos_tag(source.split())\n",
    "    pos_tags = set()\n",
    "    for pos in word_pos:\n",
    "        if (pos[1][0] == 'N') | (pos[1][0] == 'V'):\n",
    "            pos_tags.add(pos[0])\n",
    "    return list(pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_source_df['pos(nouns & verbs)'] = essay_source_df['documents'].apply(source_pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# synonyms_overlap = []\n",
    "# synonyms_overlap_prop = []\n",
    "source_overlap = []\n",
    "source_overlap_prop = []\n",
    "\n",
    "for i in range(len(source_essay)):    \n",
    "    essay_set = source_essay['essay_set'][i]\n",
    "    essay_tokens = nltk.word_tokenize(source_essay['essay_documents'][i])\n",
    "    source_tokens = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'pos(nouns & verbs)'][essay_set]\n",
    "#     synonyms = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "#     synonyms_overlap_temp = [word for word in essay_tokens if word in synonyms]\n",
    "    source_overlap_temp = [word for word in essay_tokens if word in source_tokens]\n",
    "    \n",
    "#     synonyms_overlap.append(len(synonyms_overlap_temp))\n",
    "#     synonyms_overlap_prop.append(len(synonyms_overlap_temp)/(len(essay_tokens)+1))\n",
    "    source_overlap.append(len(source_overlap_temp))\n",
    "    source_overlap_prop.append(len(source_overlap_temp)/(len(essay_tokens)+1))\n",
    "source_essay['source_overlap'] = source_overlap\n",
    "source_essay['source_overlap_prop'] = source_overlap_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_essay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-242762793360>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msource_essay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'source_essay' is not defined"
     ]
    }
   ],
   "source": [
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = essay_set1.drop(['domain1_score','essay_id','essay_set','essay','clean_essay','corrected_essay','essay_documents'],axis=1)\n",
    "y = essay_set1['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(essay_set1['essay_documents'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist() \n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abd</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abduction</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zingbobway</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  abandon  abandoned  abbreviated  abbreviation  abd  abdication  \\\n",
       "0  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "1  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "2  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "3  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "4  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "\n",
       "   abducted  abduction  abe  ...   yup  zap  zero  zingbobway      zip  \\\n",
       "0       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "1       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "2       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "3       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.09828   \n",
       "4       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "\n",
       "   zombie  zone  zoning  zoo  zoom  \n",
       "0     0.0   0.0     0.0  0.0   0.0  \n",
       "1     0.0   0.0     0.0  0.0   0.0  \n",
       "2     0.0   0.0     0.0  0.0   0.0  \n",
       "3     0.0   0.0     0.0  0.0   0.0  \n",
       "4     0.0   0.0     0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 8943 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([X,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err1</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zingbobway</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8956 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  sent_count  spell_err1  noun_count  verb_count  adv_count  \\\n",
       "0         344          16          11          78          37         15   \n",
       "1         413          20          16         103          55         10   \n",
       "2         276          14           2          74          31          4   \n",
       "3         488          27          24         134          53         24   \n",
       "4         469          30          13         117          40         11   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  syn_overlap  ...   yup  \\\n",
       "0         28              74.02           0.618182           59  ...   0.0   \n",
       "1         24              67.08           0.569444           56  ...   0.0   \n",
       "2         18              68.20           0.646154           70  ...   0.0   \n",
       "3         45              53.34           0.584559           85  ...   0.0   \n",
       "4         27              72.66           0.531818           62  ...   0.0   \n",
       "\n",
       "   zap  zero  zingbobway      zip  zombie  zone  zoning  zoo  zoom  \n",
       "0  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "1  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "2  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "3  0.0   0.0         0.0  0.09828     0.0   0.0     0.0  0.0   0.0  \n",
       "4  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 8956 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X.values,y.values,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.29000000e+02, 3.00000000e+01, 1.40000000e+01, ...,\n",
       "        2.21238938e-01, 3.90000000e+01, 1.72566372e-01],\n",
       "       [2.79000000e+02, 2.10000000e+01, 1.00000000e+01, ...,\n",
       "        2.55813953e-01, 2.20000000e+01, 1.70542636e-01],\n",
       "       [4.45000000e+02, 2.60000000e+01, 5.00000000e+00, ...,\n",
       "        2.80373832e-01, 4.20000000e+01, 1.96261682e-01],\n",
       "       ...,\n",
       "       [2.77000000e+02, 1.20000000e+01, 1.10000000e+01, ...,\n",
       "        2.63565891e-01, 2.40000000e+01, 1.86046512e-01],\n",
       "       [3.83000000e+02, 2.70000000e+01, 9.00000000e+00, ...,\n",
       "        2.28723404e-01, 2.70000000e+01, 1.43617021e-01],\n",
       "       [3.36000000e+02, 2.00000000e+01, 2.00000000e+00, ...,\n",
       "        2.58620690e-01, 2.70000000e+01, 1.55172414e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics():\n",
    "    from sklearn import metrics\n",
    "    print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Cohen\\'s kappa score: %.2f' % metrics.cohen_kappa_score(np.rint(y_pred), y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 960 candidates, totalling 2880 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=3)]: Done 359 tasks      | elapsed:   48.2s\n",
      "[Parallel(n_jobs=3)]: Done 642 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=3)]: Done 1007 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=3)]: Done 1452 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=3)]: Done 1979 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=3)]: Done 2586 tasks      | elapsed:  7.6min\n",
      "[Parallel(n_jobs=3)]: Done 2880 out of 2880 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_accuracy: 0.7246536104167913\n",
      "best_parameters: {'learning_rate': 0.05, 'max_depth': 2, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "502.8731334209442\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "GBR=GradientBoostingRegressor()\n",
    "optimization_dict = {'max_depth': [2,4,6],\n",
    "                     'n_estimators': [100,200,300,500,1000],\n",
    "                    'learning_rate':[0.01,0.05,0.1,0.5],\n",
    "                    'max_features':['auto'],\n",
    "                    'min_samples_split':[2,4,10,15],\n",
    "                    'min_samples_leaf':[2,4,10,15]}\n",
    "\n",
    "gridsearch = GridSearchCV(GBR, optimization_dict, verbose=2, cv=3,n_jobs=3)\n",
    "gridsearch.fit(X_train,y_train)\n",
    "print(\"best_accuracy:\",gridsearch.best_score_)\n",
    "print(\"best_parameters:\",gridsearch.best_params_)\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.6636596716243375\n",
      "MSE: 0.7020185224452309\n",
      "RMSE: 0.8378654560520029\n",
      "Cohen's kappa score: 0.83\n",
      "0.09994387626647949\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR=GradientBoostingRegressor()\n",
    "GBR.fit(X_train,y_train)\n",
    "y_pred = GBR.predict(X_test)\n",
    "eval_metrics()\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = GBR.predict(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({\"y_pred\":np.rint(y_pred),'y_act':y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1755</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>11.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1760</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1772</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1775</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1783 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_pred  y_act\n",
       "0        8.0      8\n",
       "1        9.0      9\n",
       "2        8.0      7\n",
       "3       10.0     10\n",
       "4        9.0      8\n",
       "5        7.0      8\n",
       "6       10.0     10\n",
       "7       10.0     10\n",
       "8        9.0      9\n",
       "9        9.0      9\n",
       "10       9.0      8\n",
       "11       8.0      8\n",
       "12       7.0      7\n",
       "13       7.0      6\n",
       "14       6.0      6\n",
       "15      11.0     12\n",
       "16       8.0      8\n",
       "17       8.0      8\n",
       "18       4.0      4\n",
       "19       6.0      6\n",
       "20       9.0      8\n",
       "21       4.0      3\n",
       "22      10.0     10\n",
       "23      10.0     11\n",
       "24       8.0      8\n",
       "25       9.0      9\n",
       "26       5.0      4\n",
       "27       9.0      9\n",
       "28       8.0      9\n",
       "29       8.0      8\n",
       "...      ...    ...\n",
       "1753    10.0     10\n",
       "1754     9.0     10\n",
       "1755    11.0     12\n",
       "1756     8.0      8\n",
       "1757     8.0      8\n",
       "1758    11.0     12\n",
       "1759     9.0      8\n",
       "1760     5.0      5\n",
       "1761     9.0      8\n",
       "1762     9.0      9\n",
       "1763     8.0      8\n",
       "1764     8.0      9\n",
       "1765    10.0     10\n",
       "1766     8.0      8\n",
       "1767    10.0     10\n",
       "1768     8.0      8\n",
       "1769    10.0     10\n",
       "1770     9.0      9\n",
       "1771     9.0      9\n",
       "1772    10.0     11\n",
       "1773     6.0      5\n",
       "1774     9.0     10\n",
       "1775    10.0      9\n",
       "1776     9.0     10\n",
       "1777     8.0      8\n",
       "1778     9.0      8\n",
       "1779     7.0      7\n",
       "1780     8.0      8\n",
       "1781     3.0      2\n",
       "1782     7.0      7\n",
       "\n",
       "[1783 rows x 2 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
