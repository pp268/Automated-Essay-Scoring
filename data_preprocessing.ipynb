{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1766,
     "status": "error",
     "timestamp": 1587236867080,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "XMFbuHfRYX4j",
    "outputId": "509072ba-55e7-4be7-d345-79749e11fabd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import textstat\n",
    "\n",
    "from feature_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQHJ_sNpYX4n"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/training_set_rel3.tsv',sep='\\t',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GtSOJ26YX4q",
    "outputId": "658c8f72-da82-46a9-9a1d-941dfa3fa4ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4zT1uANYX4t",
    "outputId": "c73c9181-91a2-4ed9-b4d0-f4bdbfde17be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 28 columns):\n",
      "essay_id          12976 non-null int64\n",
      "essay_set         12976 non-null int64\n",
      "essay             12976 non-null object\n",
      "rater1_domain1    12976 non-null int64\n",
      "rater2_domain1    12976 non-null int64\n",
      "rater3_domain1    128 non-null float64\n",
      "domain1_score     12976 non-null int64\n",
      "rater1_domain2    1800 non-null float64\n",
      "rater2_domain2    1800 non-null float64\n",
      "domain2_score     1800 non-null float64\n",
      "rater1_trait1     2292 non-null float64\n",
      "rater1_trait2     2292 non-null float64\n",
      "rater1_trait3     2292 non-null float64\n",
      "rater1_trait4     2292 non-null float64\n",
      "rater1_trait5     723 non-null float64\n",
      "rater1_trait6     723 non-null float64\n",
      "rater2_trait1     2292 non-null float64\n",
      "rater2_trait2     2292 non-null float64\n",
      "rater2_trait3     2292 non-null float64\n",
      "rater2_trait4     2292 non-null float64\n",
      "rater2_trait5     723 non-null float64\n",
      "rater2_trait6     723 non-null float64\n",
      "rater3_trait1     128 non-null float64\n",
      "rater3_trait2     128 non-null float64\n",
      "rater3_trait3     128 non-null float64\n",
      "rater3_trait4     128 non-null float64\n",
      "rater3_trait5     128 non-null float64\n",
      "rater3_trait6     128 non-null float64\n",
      "dtypes: float64(22), int64(5), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54V7B2vXYX4w"
   },
   "outputs": [],
   "source": [
    "df = df[['essay_id','essay_set','essay','domain1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6yrnocSYX4z",
    "outputId": "e9719c27-612d-49b3-8096-3dcde0411026"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgU7DMA1YX5O"
   },
   "outputs": [],
   "source": [
    "#---------------- Removing sepecial characters from essay -------\n",
    "df['clean_essay'] = df['essay'].apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJJxBavEYX5R"
   },
   "outputs": [],
   "source": [
    "#-------------- Tokenizing the essay into words ------\n",
    "df['word_tokens'] =df['clean_essay'].apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKwMs07yYX5U"
   },
   "outputs": [],
   "source": [
    "#------------- Tokenizing the essay into sentences-----\n",
    "df['sent_tokens'] =df['essay'].apply(sent_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NilcwAZ9YX5W"
   },
   "outputs": [],
   "source": [
    "#---------- Finding the number of words in the essay---------\n",
    "df['word_count'] = df['word_tokens'].apply(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzMH-FvGYX5Y"
   },
   "outputs": [],
   "source": [
    "#---------- Finding the number of sentences in the essay---------\n",
    "df['sent_count'] = df['sent_tokens'].apply(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00z72Ng3YX5a"
   },
   "outputs": [],
   "source": [
    "#----------- Finding spelling errors and replacing the errors with correct words----------\n",
    "df['spell_err'],df['corrected_essay'] = zip(*df['word_tokens'].map(check_spell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2jmgFOhYX5c"
   },
   "outputs": [],
   "source": [
    "#----------- creating essay documents for Tfidf model------------\n",
    "df['essay_documents'] = df['corrected_essay'].apply(create_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UPlUiMkYX5d"
   },
   "outputs": [],
   "source": [
    "# ------------ tokeninzing essay documents----------\n",
    "df['corrected_tokens'] = df['essay_documents'].apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJF7SH1pYX5f"
   },
   "outputs": [],
   "source": [
    "#----------POS tags-------------\n",
    "df['noun_count'], df['verb_count'], df['adv_count'], df['adj_count'] = zip(*df['corrected_tokens'].map(pos_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4znu0A2-YX5i"
   },
   "outputs": [],
   "source": [
    "#----------Readability score computation----------\n",
    "df['readability_score'] = df['essay'].apply(compute_redability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFntP0BDYX5l"
   },
   "outputs": [],
   "source": [
    "#-------------ratio of unique words to the total words---------\n",
    "df['unique_word_ratio'] = df['corrected_tokens'].apply(unique_word_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hc3ZaGNaYX5n",
    "outputId": "fc8b240f-38a9-45e8-f3ac-2fa404f1c198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>[dear, local, newspaper, think, effect, comput...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>[Dear, I, believe, that, using, computers, wil...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "      <td>[dear, believe, using, computer, benefit, u, m...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>[Dear, More, and, more, people, use, computers...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>dear people use computer not everyone agrees b...</td>\n",
       "      <td>[dear, people, use, computer, not, everyone, a...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "      <td>[dear, local, newspaper, found, many, expert, ...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "      <td>[dear, know, computer, positive, effect, peopl...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [Dear, local, newspaper, I, think, effects, co...   \n",
       "1  [Dear, I, believe, that, using, computers, wil...   \n",
       "2  [Dear, More, and, more, people, use, computers...   \n",
       "3  [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4  [Dear, I, know, having, computers, has, a, pos...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [Dear local newspaper, I think effects compute...         344          16   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...         413          20   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...         276          14   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...         488          27   \n",
       "4  [Dear @LOCATION1, I know having computers has ...         469          30   \n",
       "\n",
       "   spell_err                                    corrected_essay  \\\n",
       "0         11  Dear local newspaper I think effects computers...   \n",
       "1         16  Dear I believe that using computers will benef...   \n",
       "2          2  Dear More and more people use computers but no...   \n",
       "3         24  Dear Local Newspaper I have found that many ex...   \n",
       "4         13  Dear I know having computers has a positive ef...   \n",
       "\n",
       "                                     essay_documents  \\\n",
       "0  dear local newspaper think effect computer peo...   \n",
       "1  dear believe using computer benefit u many way...   \n",
       "2  dear people use computer not everyone agrees b...   \n",
       "3  dear local newspaper found many expert say com...   \n",
       "4  dear know computer positive effect people comp...   \n",
       "\n",
       "                                    corrected_tokens  noun_count  verb_count  \\\n",
       "0  [dear, local, newspaper, think, effect, comput...          78          37   \n",
       "1  [dear, believe, using, computer, benefit, u, m...         103          55   \n",
       "2  [dear, people, use, computer, not, everyone, a...          74          31   \n",
       "3  [dear, local, newspaper, found, many, expert, ...         134          53   \n",
       "4  [dear, know, computer, positive, effect, peopl...         117          40   \n",
       "\n",
       "   adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "0         15         28              74.02           0.618182  \n",
       "1         10         24              67.08           0.569444  \n",
       "2          4         18              68.20           0.646154  \n",
       "3         24         45              53.34           0.584559  \n",
       "4         11         27              72.66           0.531818  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Feature extraction based on the Prompt and Source of the Essay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature extraction based on the prompt and source have been done by using different approches\n",
    "for Persuasive and Source type of essay.\n",
    "\n",
    "For the persuasive type of essay, synonyms of all words(except stopwords) in the prompt have been \n",
    "collected and then finds how many words in the essay are present in the synonyms of the prompt \n",
    "words and actual prompts and the ratio of the matched words to the total words.\n",
    "\n",
    "For Source type of essays only Nouns and Verbs are used instead of all words in the souce because of \n",
    "the size of the source.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIv8o3pbYX5x"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>[In, most, stories, mothers, and, daughters, a...</td>\n",
       "      <td>[ In most stories mothers and daughters are ei...</td>\n",
       "      <td>806</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>In most stories mothers and daughters are eith...</td>\n",
       "      <td>story mother daughter either enemy friend stor...</td>\n",
       "      <td>[story, mother, daughter, either, enemy, frien...</td>\n",
       "      <td>132</td>\n",
       "      <td>73</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>56.05</td>\n",
       "      <td>0.605479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>[I, never, understood, the, meaning, laughter,...</td>\n",
       "      <td>[ I never understood the meaning laughter is t...</td>\n",
       "      <td>526</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>I never understood the meaning laughter is the...</td>\n",
       "      <td>never understood meaning laughter shortest dis...</td>\n",
       "      <td>[never, understood, meaning, laughter, shortes...</td>\n",
       "      <td>93</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.516260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "      <td>When you laugh  is   out of habit  or is   cau...</td>\n",
       "      <td>[When, you, laugh, is, out, of, habit, or, is,...</td>\n",
       "      <td>[When you laugh, is @CAPS5 out of habit, or is...</td>\n",
       "      <td>777</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>When you laugh is out of habit or is cause Wha...</td>\n",
       "      <td>laugh habit cause cause laughing even thing ca...</td>\n",
       "      <td>[laugh, habit, cause, cause, laughing, even, t...</td>\n",
       "      <td>137</td>\n",
       "      <td>88</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>60.79</td>\n",
       "      <td>0.723837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "      <td>Trippin  on fen...</td>\n",
       "      <td>[Trippin, on, fences, I, am, years, young, and...</td>\n",
       "      <td>[                               Trippin' on fe...</td>\n",
       "      <td>555</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>tripping on fences I am years young and in tho...</td>\n",
       "      <td>tripping fence year young short year ever reme...</td>\n",
       "      <td>[tripping, fence, year, young, short, year, ev...</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>72.05</td>\n",
       "      <td>0.643777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>[Many, people, believe, that, laughter, can, i...</td>\n",
       "      <td>[ Many people believe that laughter can improv...</td>\n",
       "      <td>460</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Many people believe that laughter can improve ...</td>\n",
       "      <td>many people believe laughter improve life laug...</td>\n",
       "      <td>[many, people, believe, laughter, improve, lif...</td>\n",
       "      <td>80</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>72.05</td>\n",
       "      <td>0.665138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "5870     21626          8   In most stories mothers and daughters are eit...   \n",
       "5871     21628          8   I never understood the meaning laughter is th...   \n",
       "5872     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "5873     21630          8                                 Trippin' on fen...   \n",
       "5874     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "      domain1_score                                        clean_essay  \\\n",
       "5870             35   In most stories mothers and daughters are eit...   \n",
       "5871             32   I never understood the meaning laughter is th...   \n",
       "5872             40  When you laugh  is   out of habit  or is   cau...   \n",
       "5873             40                                 Trippin  on fen...   \n",
       "5874             40   Many people believe that laughter can improve...   \n",
       "\n",
       "                                            word_tokens  \\\n",
       "5870  [In, most, stories, mothers, and, daughters, a...   \n",
       "5871  [I, never, understood, the, meaning, laughter,...   \n",
       "5872  [When, you, laugh, is, out, of, habit, or, is,...   \n",
       "5873  [Trippin, on, fences, I, am, years, young, and...   \n",
       "5874  [Many, people, believe, that, laughter, can, i...   \n",
       "\n",
       "                                            sent_tokens  word_count  \\\n",
       "5870  [ In most stories mothers and daughters are ei...         806   \n",
       "5871  [ I never understood the meaning laughter is t...         526   \n",
       "5872  [When you laugh, is @CAPS5 out of habit, or is...         777   \n",
       "5873  [                               Trippin' on fe...         555   \n",
       "5874  [ Many people believe that laughter can improv...         460   \n",
       "\n",
       "      sent_count  spell_err  \\\n",
       "5870          27          1   \n",
       "5871          35          5   \n",
       "5872          41          7   \n",
       "5873          39          3   \n",
       "5874          29          1   \n",
       "\n",
       "                                        corrected_essay  \\\n",
       "5870  In most stories mothers and daughters are eith...   \n",
       "5871  I never understood the meaning laughter is the...   \n",
       "5872  When you laugh is out of habit or is cause Wha...   \n",
       "5873  tripping on fences I am years young and in tho...   \n",
       "5874  Many people believe that laughter can improve ...   \n",
       "\n",
       "                                        essay_documents  \\\n",
       "5870  story mother daughter either enemy friend stor...   \n",
       "5871  never understood meaning laughter shortest dis...   \n",
       "5872  laugh habit cause cause laughing even thing ca...   \n",
       "5873  tripping fence year young short year ever reme...   \n",
       "5874  many people believe laughter improve life laug...   \n",
       "\n",
       "                                       corrected_tokens  noun_count  \\\n",
       "5870  [story, mother, daughter, either, enemy, frien...         132   \n",
       "5871  [never, understood, meaning, laughter, shortes...          93   \n",
       "5872  [laugh, habit, cause, cause, laughing, even, t...         137   \n",
       "5873  [tripping, fence, year, young, short, year, ev...          79   \n",
       "5874  [many, people, believe, laughter, improve, lif...          80   \n",
       "\n",
       "      verb_count  adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "5870          73         52         60              56.05           0.605479  \n",
       "5871          53         40         45              50.00           0.516260  \n",
       "5872          88         31         60              60.79           0.723837  \n",
       "5873          56         38         45              72.05           0.643777  \n",
       "5874          52         29         46              72.05           0.665138  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay = df[(df['essay_set']== 1) | (df['essay_set']== 2) | (df['essay_set']== 7) | (df['essay_set']== 8)]\n",
    "persuasive_essay.reset_index(drop=True,inplace=True)\n",
    "persuasive_essay.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tzy9rkXYX55"
   },
   "outputs": [],
   "source": [
    "prompt1 = open(\"processed_data_files/prompt/Prompt1.txt\",'r',encoding='utf-8')\n",
    "prompt1 = prompt1.read()\n",
    "prompt2 = open(\"processed_data_files/prompt/Prompt2.txt\",'r',encoding='utf-8')\n",
    "prompt2 = prompt2.read()\n",
    "prompt7 = open(\"processed_data_files/prompt/Prompt7.txt\",'r',encoding='utf-8')\n",
    "prompt7 = prompt7.read()\n",
    "prompt8 = open(\"processed_data_files/prompt/Prompt8.txt\",'r',encoding='utf-8')\n",
    "prompt8 = prompt8.read()\n",
    "\n",
    "persuasive_set = [1,2,7,8]\n",
    "prompts = [prompt1,prompt2,prompt7,prompt8]\n",
    "\n",
    "essay_prompt_df = pd.DataFrame({'essay_set':persuasive_set,'prompt':prompts},index=persuasive_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9fg3tuuYX57"
   },
   "outputs": [],
   "source": [
    "essay_prompt_df['clean_prompt'] = essay_prompt_df['prompt'].apply(remove_special_char)\n",
    "essay_prompt_df['documents'] = essay_prompt_df['clean_prompt'].apply(create_documents)\n",
    "essay_prompt_df['tokens'] = essay_prompt_df['documents'].apply(word_tokenizer)\n",
    "essay_prompt_df['synonyms'] = essay_prompt_df['tokens'].apply(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5NRpLYkYX6D",
    "outputId": "4ccd7d23-7a88-4f2d-8782-b339e1adcc62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>prompt</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>documents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>More and more people use computers  but not ev...</td>\n",
       "      <td>people use computer not everyone agrees benefi...</td>\n",
       "      <td>[people, use, computer, not, everyone, agrees,...</td>\n",
       "      <td>[overconfident, fellowship, place, clip, see, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in the Libraries\\n\"All of us can th...</td>\n",
       "      <td>Censorship in the Libraries  All of us can thi...</td>\n",
       "      <td>censorship library u think book hope none chil...</td>\n",
       "      <td>[censorship, library, u, think, book, hope, no...</td>\n",
       "      <td>[remove, depart, book, place, cerebrate, clip,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>Write about patience  Being patient means that...</td>\n",
       "      <td>write patience patient mean understanding tole...</td>\n",
       "      <td>[write, patience, patient, mean, understanding...</td>\n",
       "      <td>[fib, patient, average, receive, unitary, see,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>We all understand the benefits of laughter. Fo...</td>\n",
       "      <td>We all understand the benefits of laughter  Fo...</td>\n",
       "      <td>understand benefit laughter example someone sa...</td>\n",
       "      <td>[understand, benefit, laughter, example, someo...</td>\n",
       "      <td>[fib, set_forth, depart, unretentive, unitary,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             prompt  \\\n",
       "1          1  More and more people use computers, but not ev...   \n",
       "2          2  Censorship in the Libraries\\n\"All of us can th...   \n",
       "7          7  Write about patience. Being patient means that...   \n",
       "8          8  We all understand the benefits of laughter. Fo...   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "1  More and more people use computers  but not ev...   \n",
       "2  Censorship in the Libraries  All of us can thi...   \n",
       "7  Write about patience  Being patient means that...   \n",
       "8  We all understand the benefits of laughter  Fo...   \n",
       "\n",
       "                                           documents  \\\n",
       "1  people use computer not everyone agrees benefi...   \n",
       "2  censorship library u think book hope none chil...   \n",
       "7  write patience patient mean understanding tole...   \n",
       "8  understand benefit laughter example someone sa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "1  [people, use, computer, not, everyone, agrees,...   \n",
       "2  [censorship, library, u, think, book, hope, no...   \n",
       "7  [write, patience, patient, mean, understanding...   \n",
       "8  [understand, benefit, laughter, example, someo...   \n",
       "\n",
       "                                            synonyms  \n",
       "1  [overconfident, fellowship, place, clip, see, ...  \n",
       "2  [remove, depart, book, place, cerebrate, clip,...  \n",
       "7  [fib, patient, average, receive, unitary, see,...  \n",
       "8  [fib, set_forth, depart, unretentive, unitary,...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JF_uc3CYX6K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "synonyms_overlap = []\n",
    "synonyms_overlap_prop = []\n",
    "prompt_overlap = []\n",
    "prompt_overlap_prop = []\n",
    "\n",
    "for i in range(len(persuasive_essay)):    \n",
    "    essay_set = persuasive_essay['essay_set'][i]\n",
    "    essay_tokens = persuasive_essay['corrected_tokens'][i]\n",
    "    prompt_tokens = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'tokens'][essay_set]\n",
    "    synonyms = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "    synonyms_overlap_temp = [word for word in essay_tokens if word in synonyms]\n",
    "    prompt_overlap_temp = [word for word in essay_tokens if word in prompt_tokens]\n",
    "    \n",
    "    synonyms_overlap.append(len(synonyms_overlap_temp))\n",
    "    synonyms_overlap_prop.append(len(synonyms_overlap_temp)/(len(essay_tokens)+1))\n",
    "    prompt_overlap.append(len(prompt_overlap_temp))\n",
    "    prompt_overlap_prop.append(len(prompt_overlap_temp)/(len(essay_tokens)+1))\n",
    "\n",
    "persuasive_essay['syn_overlap'] = synonyms_overlap\n",
    "persuasive_essay['syn_overlap_prop'] = synonyms_overlap_prop\n",
    "persuasive_essay['prompt_overlap'] = prompt_overlap\n",
    "persuasive_essay['prompt_overlap_prop'] = prompt_overlap_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IE7QgH0iYX6P",
    "outputId": "c469fa21-1d28-420e-e0c3-4b38edd5aec1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>syn_overlap_prop</th>\n",
       "      <th>prompt_overlap</th>\n",
       "      <th>prompt_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>46</td>\n",
       "      <td>0.277108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>[Dear, I, believe, that, using, computers, wil...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>39</td>\n",
       "      <td>0.179724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>[Dear, More, and, more, people, use, computers...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>62</td>\n",
       "      <td>0.473282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>0.311355</td>\n",
       "      <td>55</td>\n",
       "      <td>0.201465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>51</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [Dear, local, newspaper, I, think, effects, co...   \n",
       "1  [Dear, I, believe, that, using, computers, wil...   \n",
       "2  [Dear, More, and, more, people, use, computers...   \n",
       "3  [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4  [Dear, I, know, having, computers, has, a, pos...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [Dear local newspaper, I think effects compute...         344          16   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...         413          20   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...         276          14   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...         488          27   \n",
       "4  [Dear @LOCATION1, I know having computers has ...         469          30   \n",
       "\n",
       "   spell_err         ...          noun_count verb_count adv_count  adj_count  \\\n",
       "0         11         ...                  78         37        15         28   \n",
       "1         16         ...                 103         55        10         24   \n",
       "2          2         ...                  74         31         4         18   \n",
       "3         24         ...                 134         53        24         45   \n",
       "4         13         ...                 117         40        11         27   \n",
       "\n",
       "   readability_score  unique_word_ratio  syn_overlap  syn_overlap_prop  \\\n",
       "0              74.02           0.618182           59          0.355422   \n",
       "1              67.08           0.569444           56          0.258065   \n",
       "2              68.20           0.646154           70          0.534351   \n",
       "3              53.34           0.584559           85          0.311355   \n",
       "4              72.66           0.531818           62          0.280543   \n",
       "\n",
       "   prompt_overlap  prompt_overlap_prop  \n",
       "0              46             0.277108  \n",
       "1              39             0.179724  \n",
       "2              62             0.473282  \n",
       "3              55             0.201465  \n",
       "4              51             0.230769  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZqSht1RYX6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>16629</td>\n",
       "      <td>6</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>[The, one, obstacle, the, builders, had, when,...</td>\n",
       "      <td>[The one obstacle the builders had when trying...</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>one obstacle builder trying build building not...</td>\n",
       "      <td>[one, obstacle, builder, trying, build, buildi...</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>77.27</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>16630</td>\n",
       "      <td>6</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>[Some, of, the, problems, with, the, construct...</td>\n",
       "      <td>[Some of the problems with the constructing of...</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>problem constructing docking dirigible natural...</td>\n",
       "      <td>[problem, constructing, docking, dirigible, na...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>57.30</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>16631</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>3</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>[The, builders, of, the, Empire, State, buildi...</td>\n",
       "      <td>[The builders of the Empire State building fac...</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>builder empire state building faced obstacle a...</td>\n",
       "      <td>[builder, empire, state, building, faced, obst...</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>16632</td>\n",
       "      <td>6</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>2</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>[The, obstacles, the, builders, of, the, Empir...</td>\n",
       "      <td>[The obstacles the builders of the Empire Stat...</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>obstacle builder empire state building could n...</td>\n",
       "      <td>[obstacle, builder, empire, state, building, c...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>53.89</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>16633</td>\n",
       "      <td>6</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>2</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>[You, want, me, to, tell, you, what, they, had...</td>\n",
       "      <td>[You want me to tell you what they had to go t...</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>want tell go attempt allow dirigible dock well...</td>\n",
       "      <td>[want, tell, go, attempt, allow, dirigible, do...</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>64.78</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "7096     16629          6  The one obstacle the builders had when trying ...   \n",
       "7097     16630          6  Some of the problems with the constructing of ...   \n",
       "7098     16631          6  The builders of the Empire State building face...   \n",
       "7099     16632          6  The obstacles the builders of the Empire State...   \n",
       "7100     16633          6  You want me to tell you what they had to go th...   \n",
       "\n",
       "      domain1_score                                        clean_essay  \\\n",
       "7096              0  The one obstacle the builders had when trying ...   \n",
       "7097              2  Some of the problems with the constructing of ...   \n",
       "7098              3  The builders of the Empire State building face...   \n",
       "7099              2  The obstacles the builders of the Empire State...   \n",
       "7100              2  You want me to tell you what they had to go th...   \n",
       "\n",
       "                                            word_tokens  \\\n",
       "7096  [The, one, obstacle, the, builders, had, when,...   \n",
       "7097  [Some, of, the, problems, with, the, construct...   \n",
       "7098  [The, builders, of, the, Empire, State, buildi...   \n",
       "7099  [The, obstacles, the, builders, of, the, Empir...   \n",
       "7100  [You, want, me, to, tell, you, what, they, had...   \n",
       "\n",
       "                                            sent_tokens  word_count  \\\n",
       "7096  [The one obstacle the builders had when trying...         152   \n",
       "7097  [Some of the problems with the constructing of...          66   \n",
       "7098  [The builders of the Empire State building fac...         105   \n",
       "7099  [The obstacles the builders of the Empire Stat...          68   \n",
       "7100  [You want me to tell you what they had to go t...         157   \n",
       "\n",
       "      sent_count  spell_err  \\\n",
       "7096           8         10   \n",
       "7097           3          0   \n",
       "7098           5          1   \n",
       "7099           2          1   \n",
       "7100           9          2   \n",
       "\n",
       "                                        corrected_essay  \\\n",
       "7096  The one obstacle the builders had when trying ...   \n",
       "7097  Some of the problems with the constructing of ...   \n",
       "7098  The builders of the Empire State building face...   \n",
       "7099  The obstacles the builders of the Empire State...   \n",
       "7100  You want me to tell you what they had to go th...   \n",
       "\n",
       "                                        essay_documents  \\\n",
       "7096  one obstacle builder trying build building not...   \n",
       "7097  problem constructing docking dirigible natural...   \n",
       "7098  builder empire state building faced obstacle a...   \n",
       "7099  obstacle builder empire state building could n...   \n",
       "7100  want tell go attempt allow dirigible dock well...   \n",
       "\n",
       "                                       corrected_tokens  noun_count  \\\n",
       "7096  [one, obstacle, builder, trying, build, buildi...          36   \n",
       "7097  [problem, constructing, docking, dirigible, na...          13   \n",
       "7098  [builder, empire, state, building, faced, obst...          30   \n",
       "7099  [obstacle, builder, empire, state, building, c...          18   \n",
       "7100  [want, tell, go, attempt, allow, dirigible, do...          33   \n",
       "\n",
       "      verb_count  adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "7096          13         10          9              77.27           0.706667  \n",
       "7097           8          4         11              57.30           0.925000  \n",
       "7098           8          5          9              58.62           0.814815  \n",
       "7099           7          3          5              53.89           0.810811  \n",
       "7100          19          4         14              64.78           0.632911  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay = df[(df['essay_set']== 3) | (df['essay_set']== 4) | (df['essay_set']== 5) | (df['essay_set']== 6)]\n",
    "source_essay.reset_index(drop=True,inplace=True)\n",
    "source_essay.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Go0QyU5YX6m"
   },
   "outputs": [],
   "source": [
    "source3 = open(\"processed_data_files/source/Source3.txt\",'r',encoding='utf-8')\n",
    "source3 = source3.read()\n",
    "source4 = open(\"processed_data_files/source/Source4.txt\",'r',encoding='utf-8')\n",
    "source4 = source4.read()\n",
    "source5 = open(\"processed_data_files/source/Source5.txt\",'r',encoding='utf-8')\n",
    "source5 = source5.read()\n",
    "source6 = open(\"processed_data_files/source/Source6.txt\",'r',encoding='utf-8')\n",
    "source6 = source6.read()\n",
    "\n",
    "source_set = [3,4,5,6]\n",
    "source = [source3,source4,source5,source6]\n",
    "\n",
    "essay_source_df = pd.DataFrame({'essay_set':source_set,'source':source},index=source_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBQbv9CjYX6p"
   },
   "outputs": [],
   "source": [
    "essay_source_df['clean_source'] = essay_source_df['source'].apply(remove_special_char)\n",
    "essay_source_df['documents'] = essay_source_df['clean_source'].apply(create_documents)\n",
    "essay_source_df['tokens'] = essay_source_df['documents'].apply(word_tokenizer)\n",
    "essay_source_df['pos(nouns & verbs)'] = essay_source_df['tokens'].apply(nouns_and_verbs_pos)\n",
    "essay_source_df['synonyms'] = essay_source_df['pos(nouns & verbs)'].apply(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_source</th>\n",
       "      <th>documents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos(nouns &amp; verbs)</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ROUGH ROAD AHEAD: Do Not Exceed Posted Speed L...</td>\n",
       "      <td>ROUGH ROAD AHEAD  Do Not Exceed Posted Speed L...</td>\n",
       "      <td>rough road ahead not exceed posted speed limit...</td>\n",
       "      <td>[rough, road, ahead, not, exceed, posted, spee...</td>\n",
       "      <td>[joe, face, hope, jaunt, place, energy, bait, ...</td>\n",
       "      <td>[face, twenty_dollar_bill, energy, mental_capa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Winter Hibiscus by Minfong Ho\\nSaeng, a teenag...</td>\n",
       "      <td>Winter Hibiscus by Minfong Ho Saeng  a teenage...</td>\n",
       "      <td>winter hibiscus minfong ho saeng teenage girl ...</td>\n",
       "      <td>[winter, hibiscus, minfong, ho, saeng, teenage...</td>\n",
       "      <td>[delicate, strand, lanna, moment, yes, afterno...</td>\n",
       "      <td>[mutter, shard, face, bemire, lap, equilibrise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Narciso Rodriguez\\nfrom Home: The Blueprints o...</td>\n",
       "      <td>Narciso Rodriguez from Home  The Blueprints of...</td>\n",
       "      <td>narciso rodriguez home blueprint life parent o...</td>\n",
       "      <td>[narciso, rodriguez, home, blueprint, life, pa...</td>\n",
       "      <td>[extended, arnold, blond, building, solidarity...</td>\n",
       "      <td>[face, twenty_dollar_bill, go_past, clip, warm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The Mooring Mast\\nby Marcia Amidon LÃ¼sted\\nWhe...</td>\n",
       "      <td>The Mooring Mast by Marcia Amidon L sted When ...</td>\n",
       "      <td>mooring mast marcia amidon l sted empire state...</td>\n",
       "      <td>[mooring, mast, marcia, amidon, l, sted, empir...</td>\n",
       "      <td>[weighted, designing, chrysler, learning, conc...</td>\n",
       "      <td>[desexualize, encyclopedism, ship's_company, f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             source  \\\n",
       "3          3  ROUGH ROAD AHEAD: Do Not Exceed Posted Speed L...   \n",
       "4          4  Winter Hibiscus by Minfong Ho\\nSaeng, a teenag...   \n",
       "5          5  Narciso Rodriguez\\nfrom Home: The Blueprints o...   \n",
       "6          6  The Mooring Mast\\nby Marcia Amidon LÃ¼sted\\nWhe...   \n",
       "\n",
       "                                        clean_source  \\\n",
       "3  ROUGH ROAD AHEAD  Do Not Exceed Posted Speed L...   \n",
       "4  Winter Hibiscus by Minfong Ho Saeng  a teenage...   \n",
       "5  Narciso Rodriguez from Home  The Blueprints of...   \n",
       "6  The Mooring Mast by Marcia Amidon L sted When ...   \n",
       "\n",
       "                                           documents  \\\n",
       "3  rough road ahead not exceed posted speed limit...   \n",
       "4  winter hibiscus minfong ho saeng teenage girl ...   \n",
       "5  narciso rodriguez home blueprint life parent o...   \n",
       "6  mooring mast marcia amidon l sted empire state...   \n",
       "\n",
       "                                              tokens  \\\n",
       "3  [rough, road, ahead, not, exceed, posted, spee...   \n",
       "4  [winter, hibiscus, minfong, ho, saeng, teenage...   \n",
       "5  [narciso, rodriguez, home, blueprint, life, pa...   \n",
       "6  [mooring, mast, marcia, amidon, l, sted, empir...   \n",
       "\n",
       "                                  pos(nouns & verbs)  \\\n",
       "3  [joe, face, hope, jaunt, place, energy, bait, ...   \n",
       "4  [delicate, strand, lanna, moment, yes, afterno...   \n",
       "5  [extended, arnold, blond, building, solidarity...   \n",
       "6  [weighted, designing, chrysler, learning, conc...   \n",
       "\n",
       "                                            synonyms  \n",
       "3  [face, twenty_dollar_bill, energy, mental_capa...  \n",
       "4  [mutter, shard, face, bemire, lap, equilibrise...  \n",
       "5  [face, twenty_dollar_bill, go_past, clip, warm...  \n",
       "6  [desexualize, encyclopedism, ship's_company, f...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xbpt2PLZYX6z",
    "outputId": "2fd9962d-54a9-4729-fd2e-a97e39bf38e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "synonyms_overlap = []\n",
    "synonyms_overlap_prop = []\n",
    "\n",
    "source_overlap = []\n",
    "source_overlap_prop = []\n",
    "\n",
    "for i in range(len(source_essay)):\n",
    "    \n",
    "    essay_set = source_essay['essay_set'][i]\n",
    "    essay_tokens = source_essay['corrected_tokens'][i]\n",
    "    \n",
    "    source_tokens = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'pos(nouns & verbs)'][essay_set]\n",
    "    source_overlap_temp = [word for word in essay_tokens if word in source_tokens]\n",
    "    source_overlap.append(len(source_overlap_temp))\n",
    "    source_overlap_prop.append(len(source_overlap_temp)/(len(essay_tokens)+1))\n",
    "\n",
    "    synonyms = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "    synonyms_overlap_temp = [word for word in essay_tokens if word in synonyms]    \n",
    "    synonyms_overlap.append(len(synonyms_overlap_temp))\n",
    "    synonyms_overlap_prop.append(len(synonyms_overlap_temp)/(len(essay_tokens)+1))\n",
    "\n",
    "source_essay['source_overlap'] = source_overlap\n",
    "source_essay['source_overlap_prop'] = source_overlap_prop\n",
    "source_essay['synonyms_overlap'] = synonyms_overlap\n",
    "source_essay['synonyms_overlap_prop'] = synonyms_overlap_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaS34plkYX61",
    "outputId": "dfdd7ac0-5ac6-4fe4-df35-d99210889826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>source_overlap</th>\n",
       "      <th>source_overlap_prop</th>\n",
       "      <th>synonyms_overlap</th>\n",
       "      <th>synonyms_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>[The, features, of, the, setting, affect, the,...</td>\n",
       "      <td>[The features of the setting affect the cyclis...</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>71.14</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>14</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>[The, features, of, the, setting, affected, th...</td>\n",
       "      <td>[The features of the setting affected the cycl...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>62.92</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>40</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1</td>\n",
       "      <td>Everyone travels to unfamiliar places  Sometim...</td>\n",
       "      <td>[Everyone, travels, to, unfamiliar, places, So...</td>\n",
       "      <td>[Everyone travels to unfamiliar places., Somet...</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>72.36</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>19</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5981</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>[I, believe, the, features, of, the, cyclist, ...</td>\n",
       "      <td>[I believe the features of the cyclist affecte...</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>10</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>15</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>[The, setting, effects, the, cyclist, because,...</td>\n",
       "      <td>[The setting effects the cyclist because of th...</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>51.89</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>19</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>28</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      5978          3  The features of the setting affect the cyclist...   \n",
       "1      5979          3  The features of the setting affected the cycli...   \n",
       "2      5980          3  Everyone travels to unfamiliar places. Sometim...   \n",
       "3      5981          3  I believe the features of the cyclist affected...   \n",
       "4      5982          3  The setting effects the cyclist because of the...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              1  The features of the setting affect the cyclist...   \n",
       "1              2  The features of the setting affected the cycli...   \n",
       "2              1  Everyone travels to unfamiliar places  Sometim...   \n",
       "3              1  I believe the features of the cyclist affected...   \n",
       "4              2  The setting effects the cyclist because of the...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [The, features, of, the, setting, affect, the,...   \n",
       "1  [The, features, of, the, setting, affected, th...   \n",
       "2  [Everyone, travels, to, unfamiliar, places, So...   \n",
       "3  [I, believe, the, features, of, the, cyclist, ...   \n",
       "4  [The, setting, effects, the, cyclist, because,...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [The features of the setting affect the cyclis...          51           3   \n",
       "1  [The features of the setting affected the cycl...         174          12   \n",
       "2  [Everyone travels to unfamiliar places., Somet...          96           8   \n",
       "3  [I believe the features of the cyclist affecte...          87           3   \n",
       "4  [The setting effects the cyclist because of th...         133           3   \n",
       "\n",
       "   spell_err          ...           noun_count verb_count adv_count  \\\n",
       "0          1          ...                   11          5         0   \n",
       "1         11          ...                   39         15         6   \n",
       "2          0          ...                   19         12         7   \n",
       "3         10          ...                   15          9         3   \n",
       "4          8          ...                   27         16         3   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  source_overlap  \\\n",
       "0          5              71.14           0.714286               8   \n",
       "1         17              62.92           0.800000              41   \n",
       "2          9              72.36           0.816327              19   \n",
       "3         12              53.21           0.951220              10   \n",
       "4         14              51.89           0.661538              19   \n",
       "\n",
       "   source_overlap_prop  synonyms_overlap  synonyms_overlap_prop  \n",
       "0             0.363636                14               0.636364  \n",
       "1             0.476744                40               0.465116  \n",
       "2             0.380000                24               0.480000  \n",
       "3             0.238095                15               0.357143  \n",
       "4             0.287879                28               0.424242  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving all processed data into pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Qm-ZzV2YX6F"
   },
   "outputs": [],
   "source": [
    "df.to_pickle('processed_data_files/clean_df')\n",
    "\n",
    "essay_prompt_df.to_pickle('processed_data_files/essay_prompt_df')\n",
    "\n",
    "persuasive_essay.to_pickle('processed_data_files/persuasive_essay')\n",
    "\n",
    "for i in [1,2,7,8]:\n",
    "    essay_set = persuasive_essay[persuasive_essay['essay_set']==i]\n",
    "    essay_set.to_pickle('processed_data_files/essay set/essay_set' + str(i))\n",
    "\n",
    "essay_source_df.to_pickle('processed_data_files/essay_source_df')\n",
    "source_essay.to_pickle('processed_data_files/source_essay')\n",
    "\n",
    "\n",
    "for i in [3,4,5,6]:\n",
    "    essay_set = source_essay[source_essay['essay_set']==i]\n",
    "    essay_set.to_pickle('processed_data_files/essay set/' +'essay_set' + str(i))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AES _2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
