{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import textstat\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from feature_extractor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_set1 = pd.read_pickle('processed_data_files/essay set/essay_set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = essay_set1.drop(['essay_id','essay_set','essay','domain1_score','clean_essay','word_tokens','sent_tokens','corrected_essay','essay_documents','corrected_tokens'],axis=1)\n",
    "y = essay_set1['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------TFIDF Model-----------------\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(essay_set1['essay_documents'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist() \n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([X,df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zingbobway</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8956 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  sent_count  spell_err  noun_count  verb_count  adv_count  \\\n",
       "0         344          16         11          78          37         15   \n",
       "1         413          20         16         103          55         10   \n",
       "2         276          14          2          74          31          4   \n",
       "3         488          27         24         134          53         24   \n",
       "4         469          30         13         117          40         11   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  syn_overlap  ...   yup  \\\n",
       "0         28              74.02           0.618182           59  ...   0.0   \n",
       "1         24              67.08           0.569444           56  ...   0.0   \n",
       "2         18              68.20           0.646154           70  ...   0.0   \n",
       "3         45              53.34           0.584559           85  ...   0.0   \n",
       "4         27              72.66           0.531818           62  ...   0.0   \n",
       "\n",
       "   zap  zero  zingbobway      zip  zombie  zone  zoning  zoo  zoom  \n",
       "0  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "1  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "2  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "3  0.0   0.0         0.0  0.09828     0.0   0.0     0.0  0.0   0.0  \n",
       "4  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 8956 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics():\n",
    "    print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Cohen\\'s kappa score: %.2f' % metrics.cohen_kappa_score(np.rint(y_pred), y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(final_df,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=GradientBoostingRegressor()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.593967341789098\n",
      "MSE: 0.6143690678285865\n",
      "RMSE: 0.7838169861827354\n",
      "Cohen's kappa score: 0.84\n"
     ]
    }
   ],
   "source": [
    "eval_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Function for creating features of the essays input by users ###############\n",
    "\n",
    "def create_data(essay,essay_set,essay_prompt_df,essay_source_df,vectorizer):\n",
    "    clean_essay = remove_special_char(essay)\n",
    "    word_tokens = word_tokenizer(clean_essay)\n",
    "    sent_tokens = sent_tokenizer(essay)\n",
    "    word_count = count(word_tokens)\n",
    "    sent_count = count(sent_tokens)\n",
    "    spell_err , corrected_essay = check_spell(word_tokens)\n",
    "    essay_documents = create_documents(corrected_essay)\n",
    "    corrected_tokens = word_tokenizer(essay_documents)\n",
    "    noun_count,verb_count,adv_count,adj_count = pos_count(corrected_tokens)\n",
    "    readability_score = compute_redability(essay)\n",
    "    unique_word_ratio = unique_word_prop(corrected_tokens)\n",
    "    \n",
    "    if essay_set in [1,2,7,8]:\n",
    "        prompt_tokens = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'tokens'][essay_set]\n",
    "        synonyms = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "        synonyms_overlap_temp = [word for word in corrected_tokens if word in synonyms]\n",
    "        prompt_overlap_temp = [word for word in corrected_tokens if word in prompt_tokens]\n",
    "        synonyms_overlap = (len(synonyms_overlap_temp))\n",
    "        synonyms_overlap_prop = (len(synonyms_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        prompt_overlap = (len(prompt_overlap_temp))\n",
    "        prompt_overlap_prop = (len(prompt_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        \n",
    "        X = pd.DataFrame({'word_count' : word_count, 'sent_count' : sent_count, 'spell_err' : spell_err,'noun_count': noun_count,\n",
    "                        'verb_count' : verb_count,'adv_count':adv_count, 'adj_count':adj_count, 'readability_score':readability_score, \n",
    "                        'unique_word_ratio':unique_word_ratio,'syn_overlap':synonyms_overlap, 'syn_overlap_prop':synonyms_overlap_prop,\n",
    "                        'prompt_overlap':prompt_overlap,'prompt_overlap_prop':prompt_overlap_prop},index=[0])\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        source_tokens = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'pos(nouns & verbs)'][essay_set]\n",
    "        source_overlap_temp = [word for word in corrected_tokens if word in source_tokens]\n",
    "        source_overlap = (len(source_overlap_temp))\n",
    "        source_overlap_prop = (len(source_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        synonyms = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "        synonyms_overlap_temp = [word for word in corrected_tokens if word in synonyms]    \n",
    "        synonyms_overlap = (len(synonyms_overlap_temp))\n",
    "        synonyms_overlap_prop = (len(synonyms_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        \n",
    "        X = pd.DataFrame({'word_count' : word_count, 'sent_count' : sent_count, 'spell_err' : spell_err,'noun_count': noun_count,\n",
    "                        'verb_count' : verb_count,'adv_count':adv_count, 'adj_count':adj_count, 'readability_score':readability_score, \n",
    "                        'unique_word_ratio':unique_word_ratio,'syn_overlap':synonyms_overlap, 'syn_overlap_prop':synonyms_overlap_prop,\n",
    "                        'source_overlap':source_overlap,'source_overlap_prop':source_overlap_prop},index=[0])\n",
    "    \n",
    "    vectors = vectorizer.transform([essay_documents])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist() \n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "    \n",
    "    final_df = pd.concat([X,df],axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 8.0\n"
     ]
    }
   ],
   "source": [
    "########### Score prediction of the user input essay##############\n",
    "\n",
    "essay = essay_set1['essay'][0]\n",
    "essay_prompt_df = pd.read_pickle('processed_data_files/essay_prompt_df')\n",
    "essay_source_df = pd.read_pickle('processed_data_files/essay_source_df')\n",
    "df = create_data(essay,7,essay_prompt_df,essay_source_df,vectorizer)\n",
    "pred = regressor.predict(df)\n",
    "pred = np.rint(pred)\n",
    "print(\"Score:\",pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
