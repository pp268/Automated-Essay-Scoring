{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1766,
     "status": "error",
     "timestamp": 1587236867080,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "XMFbuHfRYX4j",
    "outputId": "509072ba-55e7-4be7-d345-79749e11fabd"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import enchant\n",
    "from spellchecker import SpellChecker\n",
    "import time\n",
    "from nltk.corpus import wordnet\n",
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tQHJ_sNpYX4n"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/training_set_rel3.tsv',sep='\\t',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6GtSOJ26YX4q",
    "outputId": "658c8f72-da82-46a9-9a1d-941dfa3fa4ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "      <th>rater2_domain1</th>\n",
       "      <th>rater3_domain1</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>rater1_domain2</th>\n",
       "      <th>rater2_domain2</th>\n",
       "      <th>domain2_score</th>\n",
       "      <th>...</th>\n",
       "      <th>rater2_trait3</th>\n",
       "      <th>rater2_trait4</th>\n",
       "      <th>rater2_trait5</th>\n",
       "      <th>rater2_trait6</th>\n",
       "      <th>rater3_trait1</th>\n",
       "      <th>rater3_trait2</th>\n",
       "      <th>rater3_trait3</th>\n",
       "      <th>rater3_trait4</th>\n",
       "      <th>rater3_trait5</th>\n",
       "      <th>rater3_trait6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
       "0               4               4             NaN              8   \n",
       "1               5               4             NaN              9   \n",
       "2               4               3             NaN              7   \n",
       "3               5               5             NaN             10   \n",
       "4               4               4             NaN              8   \n",
       "\n",
       "   rater1_domain2  rater2_domain2  domain2_score      ...        \\\n",
       "0             NaN             NaN            NaN      ...         \n",
       "1             NaN             NaN            NaN      ...         \n",
       "2             NaN             NaN            NaN      ...         \n",
       "3             NaN             NaN            NaN      ...         \n",
       "4             NaN             NaN            NaN      ...         \n",
       "\n",
       "   rater2_trait3  rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  \\\n",
       "0            NaN            NaN            NaN            NaN            NaN   \n",
       "1            NaN            NaN            NaN            NaN            NaN   \n",
       "2            NaN            NaN            NaN            NaN            NaN   \n",
       "3            NaN            NaN            NaN            NaN            NaN   \n",
       "4            NaN            NaN            NaN            NaN            NaN   \n",
       "\n",
       "   rater3_trait2  rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
       "0            NaN            NaN            NaN            NaN            NaN  \n",
       "1            NaN            NaN            NaN            NaN            NaN  \n",
       "2            NaN            NaN            NaN            NaN            NaN  \n",
       "3            NaN            NaN            NaN            NaN            NaN  \n",
       "4            NaN            NaN            NaN            NaN            NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4zT1uANYX4t",
    "outputId": "c73c9181-91a2-4ed9-b4d0-f4bdbfde17be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12976 entries, 0 to 12975\n",
      "Data columns (total 28 columns):\n",
      "essay_id          12976 non-null int64\n",
      "essay_set         12976 non-null int64\n",
      "essay             12976 non-null object\n",
      "rater1_domain1    12976 non-null int64\n",
      "rater2_domain1    12976 non-null int64\n",
      "rater3_domain1    128 non-null float64\n",
      "domain1_score     12976 non-null int64\n",
      "rater1_domain2    1800 non-null float64\n",
      "rater2_domain2    1800 non-null float64\n",
      "domain2_score     1800 non-null float64\n",
      "rater1_trait1     2292 non-null float64\n",
      "rater1_trait2     2292 non-null float64\n",
      "rater1_trait3     2292 non-null float64\n",
      "rater1_trait4     2292 non-null float64\n",
      "rater1_trait5     723 non-null float64\n",
      "rater1_trait6     723 non-null float64\n",
      "rater2_trait1     2292 non-null float64\n",
      "rater2_trait2     2292 non-null float64\n",
      "rater2_trait3     2292 non-null float64\n",
      "rater2_trait4     2292 non-null float64\n",
      "rater2_trait5     723 non-null float64\n",
      "rater2_trait6     723 non-null float64\n",
      "rater3_trait1     128 non-null float64\n",
      "rater3_trait2     128 non-null float64\n",
      "rater3_trait3     128 non-null float64\n",
      "rater3_trait4     128 non-null float64\n",
      "rater3_trait5     128 non-null float64\n",
      "rater3_trait6     128 non-null float64\n",
      "dtypes: float64(22), int64(5), object(1)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54V7B2vXYX4w"
   },
   "outputs": [],
   "source": [
    "df = df[['essay_id','essay_set','essay','domain1_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6yrnocSYX4z",
    "outputId": "e9719c27-612d-49b3-8096-3dcde0411026"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-x_jt7HdYX41"
   },
   "outputs": [],
   "source": [
    "def remove_special_char(essay):\n",
    "    return re.sub('@\\S+|[^A-Za-z0-9]',' ',essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SShj8QxpYX44"
   },
   "outputs": [],
   "source": [
    "def word_tokenizer(essay):\n",
    "    return nltk.word_tokenize(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJ7HC38yYX48"
   },
   "outputs": [],
   "source": [
    "def sent_tokenizer(essay):\n",
    "    return nltk.sent_tokenize(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXjnqeYNYX4-"
   },
   "outputs": [],
   "source": [
    "def count(tokens):\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3wHcsZINYX5B"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def punct_count(essay):\n",
    "    count = 0\n",
    "    punctuations = string.punctuation\n",
    "    for char in essay:\n",
    "        if char in punctuations:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyGBECQMYX5D"
   },
   "outputs": [],
   "source": [
    "def check_spell(words):\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    spell = SpellChecker()\n",
    "    misspelled = set()\n",
    "    err_count = 0\n",
    "    for word in words:\n",
    "        if d.check(word) == False:\n",
    "            misspelled.add(word)\n",
    "            err_count += 1\n",
    "    corr_dict = {}\n",
    "    for word in misspelled:\n",
    "        corr_dict[word] = spell.correction(word)\n",
    "    essay_df = pd.DataFrame(words)\n",
    "    essay_df.replace(corr_dict,inplace=True)\n",
    "    essay = ' '.join(list(essay_df[0]))\n",
    "    return err_count,essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4mYI9KOaYX5G"
   },
   "outputs": [],
   "source": [
    "def create_documents(essay):\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    stop_words.remove('not')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    essay = essay.lower()\n",
    "    essay = nltk.word_tokenize(essay)\n",
    "    essay=[lemmatizer.lemmatize(word) for word in essay if not word in stop_words]\n",
    "    essay=' '.join(essay)\n",
    "    return essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83d0xUlHYX5I"
   },
   "outputs": [],
   "source": [
    "def pos_count(tokens):\n",
    "    noun_count = 0\n",
    "    verb_count = 0\n",
    "    adv_count = 0\n",
    "    adj_count = 0\n",
    "    word_pos = nltk.pos_tag(tokens)\n",
    "    for pos in word_pos:\n",
    "        if pos[1][0] == 'N':\n",
    "            noun_count += 1\n",
    "        elif pos[1][0] == 'V':\n",
    "            verb_count += 1\n",
    "        elif pos[1][0] == 'J':\n",
    "            adj_count += 1\n",
    "        elif pos[1][0] == 'R':\n",
    "            adv_count += 1\n",
    "    return noun_count, verb_count, adv_count, adj_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O0EpIniOYX5K"
   },
   "outputs": [],
   "source": [
    "def compute_redability(essay):\n",
    "    return textstat.flesch_reading_ease(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evrhrwd6YX5M"
   },
   "outputs": [],
   "source": [
    "def unique_word_prop(tokens):\n",
    "    ratio = len(set(tokens))/len(tokens)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AgU7DMA1YX5O"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5be04f3246e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clean_essay'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremove_special_char\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['clean_essay'] = df['essay'].apply(remove_special_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LJJxBavEYX5R"
   },
   "outputs": [],
   "source": [
    "df['word_tokens'] =df['clean_essay'].apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UKwMs07yYX5U"
   },
   "outputs": [],
   "source": [
    "df['sent_tokens'] =df['essay'].apply(sent_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NilcwAZ9YX5W"
   },
   "outputs": [],
   "source": [
    "df['word_count'] = df['word_tokens'].apply(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KzMH-FvGYX5Y"
   },
   "outputs": [],
   "source": [
    "df['sent_count'] = df['sent_tokens'].apply(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "00z72Ng3YX5a"
   },
   "outputs": [],
   "source": [
    "df['spell_err'],df['corrected_essay'] = zip(*df['word_tokens'].map(check_spell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2jmgFOhYX5c"
   },
   "outputs": [],
   "source": [
    "df['essay_documents'] = df['corrected_essay'].apply(create_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-UPlUiMkYX5d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ee1095315e88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'corrected_tokens'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_documents'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['corrected_tokens'] = df['essay_documents'].apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yJF7SH1pYX5f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-8dc5a7f52c2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'noun_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'verb_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adv_count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'adj_count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'corrected_tokens'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['noun_count'], df['verb_count'], df['adv_count'], df['adj_count'] = zip(*df['corrected_tokens'].map(pos_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4znu0A2-YX5i"
   },
   "outputs": [],
   "source": [
    "df['readability_score'] = df['essay'].apply(compute_redability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFntP0BDYX5l"
   },
   "outputs": [],
   "source": [
    "df['unique_word_ratio'] = df['corrected_tokens'].apply(unique_word_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hc3ZaGNaYX5n",
    "outputId": "fc8b240f-38a9-45e8-f3ac-2fa404f1c198"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>[dear, local, newspaper, think, effect, comput...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>[Dear, I, believe, that, using, computers, wil...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "      <td>[dear, believe, using, computer, benefit, u, m...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>[Dear, More, and, more, people, use, computers...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>dear people use computer not everyone agrees b...</td>\n",
       "      <td>[dear, people, use, computer, not, everyone, a...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "      <td>[dear, local, newspaper, found, many, expert, ...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "      <td>[dear, know, computer, positive, effect, peopl...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [Dear, local, newspaper, I, think, effects, co...   \n",
       "1  [Dear, I, believe, that, using, computers, wil...   \n",
       "2  [Dear, More, and, more, people, use, computers...   \n",
       "3  [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4  [Dear, I, know, having, computers, has, a, pos...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [Dear local newspaper, I think effects compute...         344          16   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...         413          20   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...         276          14   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...         488          27   \n",
       "4  [Dear @LOCATION1, I know having computers has ...         469          30   \n",
       "\n",
       "   spell_err                                    corrected_essay  \\\n",
       "0         11  Dear local newspaper I think effects computers...   \n",
       "1         16  Dear I believe that using computers will benef...   \n",
       "2          2  Dear More and more people use computers but no...   \n",
       "3         24  Dear Local Newspaper I have found that many ex...   \n",
       "4         13  Dear I know having computers has a positive ef...   \n",
       "\n",
       "                                     essay_documents  \\\n",
       "0  dear local newspaper think effect computer peo...   \n",
       "1  dear believe using computer benefit u many way...   \n",
       "2  dear people use computer not everyone agrees b...   \n",
       "3  dear local newspaper found many expert say com...   \n",
       "4  dear know computer positive effect people comp...   \n",
       "\n",
       "                                    corrected_tokens  noun_count  verb_count  \\\n",
       "0  [dear, local, newspaper, think, effect, comput...          78          37   \n",
       "1  [dear, believe, using, computer, benefit, u, m...         103          55   \n",
       "2  [dear, people, use, computer, not, everyone, a...          74          31   \n",
       "3  [dear, local, newspaper, found, many, expert, ...         134          53   \n",
       "4  [dear, know, computer, positive, effect, peopl...         117          40   \n",
       "\n",
       "   adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "0         15         28              74.02           0.618182  \n",
       "1         10         24              67.08           0.569444  \n",
       "2          4         18              68.20           0.646154  \n",
       "3         24         45              53.34           0.584559  \n",
       "4         11         27              72.66           0.531818  "
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9aIw3BfgYX5p"
   },
   "outputs": [],
   "source": [
    "df.to_pickle('clean_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3jpm5_MYX5r"
   },
   "outputs": [],
   "source": [
    "clean_df = pd.read_pickle(\"clean_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8hM2y1I_YX5t",
    "outputId": "e64da16a-90cd-49f6-d03e-5aa383743868"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Dear local newspaper I think effects computers...</td>\n",
       "      <td>dear local newspaper think effect computer peo...</td>\n",
       "      <td>[dear, local, newspaper, think, effect, comput...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>[Dear, I, believe, that, using, computers, wil...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>Dear I believe that using computers will benef...</td>\n",
       "      <td>dear believe using computer benefit u many way...</td>\n",
       "      <td>[dear, believe, using, computer, benefit, u, m...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>[Dear, More, and, more, people, use, computers...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>Dear More and more people use computers but no...</td>\n",
       "      <td>dear people use computer not everyone agrees b...</td>\n",
       "      <td>[dear, people, use, computer, not, everyone, a...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
       "      <td>dear local newspaper found many expert say com...</td>\n",
       "      <td>[dear, local, newspaper, found, many, expert, ...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>Dear I know having computers has a positive ef...</td>\n",
       "      <td>dear know computer positive effect people comp...</td>\n",
       "      <td>[dear, know, computer, positive, effect, peopl...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [Dear, local, newspaper, I, think, effects, co...   \n",
       "1  [Dear, I, believe, that, using, computers, wil...   \n",
       "2  [Dear, More, and, more, people, use, computers...   \n",
       "3  [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4  [Dear, I, know, having, computers, has, a, pos...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [Dear local newspaper, I think effects compute...         344          16   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...         413          20   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...         276          14   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...         488          27   \n",
       "4  [Dear @LOCATION1, I know having computers has ...         469          30   \n",
       "\n",
       "   spell_err                                    corrected_essay  \\\n",
       "0         11  Dear local newspaper I think effects computers...   \n",
       "1         16  Dear I believe that using computers will benef...   \n",
       "2          2  Dear More and more people use computers but no...   \n",
       "3         24  Dear Local Newspaper I have found that many ex...   \n",
       "4         13  Dear I know having computers has a positive ef...   \n",
       "\n",
       "                                     essay_documents  \\\n",
       "0  dear local newspaper think effect computer peo...   \n",
       "1  dear believe using computer benefit u many way...   \n",
       "2  dear people use computer not everyone agrees b...   \n",
       "3  dear local newspaper found many expert say com...   \n",
       "4  dear know computer positive effect people comp...   \n",
       "\n",
       "                                    corrected_tokens  noun_count  verb_count  \\\n",
       "0  [dear, local, newspaper, think, effect, comput...          78          37   \n",
       "1  [dear, believe, using, computer, benefit, u, m...         103          55   \n",
       "2  [dear, people, use, computer, not, everyone, a...          74          31   \n",
       "3  [dear, local, newspaper, found, many, expert, ...         134          53   \n",
       "4  [dear, know, computer, positive, effect, peopl...         117          40   \n",
       "\n",
       "   adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "0         15         28              74.02           0.618182  \n",
       "1         10         24              67.08           0.569444  \n",
       "2          4         18              68.20           0.646154  \n",
       "3         24         45              53.34           0.584559  \n",
       "4         11         27              72.66           0.531818  "
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIv8o3pbYX5x"
   },
   "outputs": [],
   "source": [
    "persuasive_essay = clean_df[(clean_df['essay_set']== 1) | (clean_df['essay_set']== 2) | (clean_df['essay_set']== 7) | (clean_df['essay_set']== 8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EYZkUOZfYX5z"
   },
   "outputs": [],
   "source": [
    "persuasive_essay.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5eoZ5NQVYX51",
    "outputId": "5e38cf90-5e26-476e-b8a2-a2865ac5a302"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5870</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>[In, most, stories, mothers, and, daughters, a...</td>\n",
       "      <td>[ In most stories mothers and daughters are ei...</td>\n",
       "      <td>806</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>In most stories mothers and daughters are eith...</td>\n",
       "      <td>story mother daughter either enemy friend stor...</td>\n",
       "      <td>[story, mother, daughter, either, enemy, frien...</td>\n",
       "      <td>132</td>\n",
       "      <td>73</td>\n",
       "      <td>52</td>\n",
       "      <td>60</td>\n",
       "      <td>56.05</td>\n",
       "      <td>0.605479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5871</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>[I, never, understood, the, meaning, laughter,...</td>\n",
       "      <td>[ I never understood the meaning laughter is t...</td>\n",
       "      <td>526</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>I never understood the meaning laughter is the...</td>\n",
       "      <td>never understood meaning laughter shortest dis...</td>\n",
       "      <td>[never, understood, meaning, laughter, shortes...</td>\n",
       "      <td>93</td>\n",
       "      <td>53</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.516260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5872</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "      <td>When you laugh  is   out of habit  or is   cau...</td>\n",
       "      <td>[When, you, laugh, is, out, of, habit, or, is,...</td>\n",
       "      <td>[When you laugh, is @CAPS5 out of habit, or is...</td>\n",
       "      <td>777</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>When you laugh is out of habit or is cause Wha...</td>\n",
       "      <td>laugh habit cause cause laughing even thing ca...</td>\n",
       "      <td>[laugh, habit, cause, cause, laughing, even, t...</td>\n",
       "      <td>137</td>\n",
       "      <td>88</td>\n",
       "      <td>31</td>\n",
       "      <td>60</td>\n",
       "      <td>60.79</td>\n",
       "      <td>0.723837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5873</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "      <td>Trippin  on fen...</td>\n",
       "      <td>[Trippin, on, fences, I, am, years, young, and...</td>\n",
       "      <td>[                               Trippin' on fe...</td>\n",
       "      <td>555</td>\n",
       "      <td>39</td>\n",
       "      <td>3</td>\n",
       "      <td>tripping on fences I am years young and in tho...</td>\n",
       "      <td>tripping fence year young short year ever reme...</td>\n",
       "      <td>[tripping, fence, year, young, short, year, ev...</td>\n",
       "      <td>79</td>\n",
       "      <td>56</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "      <td>72.05</td>\n",
       "      <td>0.643777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>[Many, people, believe, that, laughter, can, i...</td>\n",
       "      <td>[ Many people believe that laughter can improv...</td>\n",
       "      <td>460</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Many people believe that laughter can improve ...</td>\n",
       "      <td>many people believe laughter improve life laug...</td>\n",
       "      <td>[many, people, believe, laughter, improve, lif...</td>\n",
       "      <td>80</td>\n",
       "      <td>52</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>72.05</td>\n",
       "      <td>0.665138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "5870     21626          8   In most stories mothers and daughters are eit...   \n",
       "5871     21628          8   I never understood the meaning laughter is th...   \n",
       "5872     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "5873     21630          8                                 Trippin' on fen...   \n",
       "5874     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "      domain1_score                                        clean_essay  \\\n",
       "5870             35   In most stories mothers and daughters are eit...   \n",
       "5871             32   I never understood the meaning laughter is th...   \n",
       "5872             40  When you laugh  is   out of habit  or is   cau...   \n",
       "5873             40                                 Trippin  on fen...   \n",
       "5874             40   Many people believe that laughter can improve...   \n",
       "\n",
       "                                            word_tokens  \\\n",
       "5870  [In, most, stories, mothers, and, daughters, a...   \n",
       "5871  [I, never, understood, the, meaning, laughter,...   \n",
       "5872  [When, you, laugh, is, out, of, habit, or, is,...   \n",
       "5873  [Trippin, on, fences, I, am, years, young, and...   \n",
       "5874  [Many, people, believe, that, laughter, can, i...   \n",
       "\n",
       "                                            sent_tokens  word_count  \\\n",
       "5870  [ In most stories mothers and daughters are ei...         806   \n",
       "5871  [ I never understood the meaning laughter is t...         526   \n",
       "5872  [When you laugh, is @CAPS5 out of habit, or is...         777   \n",
       "5873  [                               Trippin' on fe...         555   \n",
       "5874  [ Many people believe that laughter can improv...         460   \n",
       "\n",
       "      sent_count  spell_err  \\\n",
       "5870          27          1   \n",
       "5871          35          5   \n",
       "5872          41          7   \n",
       "5873          39          3   \n",
       "5874          29          1   \n",
       "\n",
       "                                        corrected_essay  \\\n",
       "5870  In most stories mothers and daughters are eith...   \n",
       "5871  I never understood the meaning laughter is the...   \n",
       "5872  When you laugh is out of habit or is cause Wha...   \n",
       "5873  tripping on fences I am years young and in tho...   \n",
       "5874  Many people believe that laughter can improve ...   \n",
       "\n",
       "                                        essay_documents  \\\n",
       "5870  story mother daughter either enemy friend stor...   \n",
       "5871  never understood meaning laughter shortest dis...   \n",
       "5872  laugh habit cause cause laughing even thing ca...   \n",
       "5873  tripping fence year young short year ever reme...   \n",
       "5874  many people believe laughter improve life laug...   \n",
       "\n",
       "                                       corrected_tokens  noun_count  \\\n",
       "5870  [story, mother, daughter, either, enemy, frien...         132   \n",
       "5871  [never, understood, meaning, laughter, shortes...          93   \n",
       "5872  [laugh, habit, cause, cause, laughing, even, t...         137   \n",
       "5873  [tripping, fence, year, young, short, year, ev...          79   \n",
       "5874  [many, people, believe, laughter, improve, lif...          80   \n",
       "\n",
       "      verb_count  adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "5870          73         52         60              56.05           0.605479  \n",
       "5871          53         40         45              50.00           0.516260  \n",
       "5872          88         31         60              60.79           0.723837  \n",
       "5873          56         38         45              72.05           0.643777  \n",
       "5874          52         29         46              72.05           0.665138  "
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J6dUBMKAYX53"
   },
   "outputs": [],
   "source": [
    "prompt1 = open(\"Prompt1.txt\",'r',encoding='utf-8')\n",
    "prompt1 = prompt1.read()\n",
    "prompt2 = open(\"Prompt2.txt\",'r',encoding='utf-8')\n",
    "prompt2 = prompt2.read()\n",
    "prompt7 = open(\"Prompt7.txt\",'r',encoding='utf-8')\n",
    "prompt7 = prompt7.read()\n",
    "prompt8 = open(\"Prompt8.txt\",'r',encoding='utf-8')\n",
    "prompt8 = prompt8.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-tzy9rkXYX55"
   },
   "outputs": [],
   "source": [
    "persuasive_set = [1,2,7,8]\n",
    "prompts = [prompt1,prompt2,prompt7,prompt8]\n",
    "essay_prompt_df = pd.DataFrame({'essay_set':persuasive_set,'prompt':prompts},index=persuasive_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l9fg3tuuYX57"
   },
   "outputs": [],
   "source": [
    "essay_prompt_df['clean_prompt'] = essay_prompt_df['prompt'].apply(remove_special_char)\n",
    "essay_prompt_df['documents'] = essay_prompt_df['clean_prompt'].apply(create_documents)\n",
    "essay_prompt_df['tokens'] = essay_prompt_df['documents'].apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMhK63gqYX59",
    "outputId": "b9a385fb-e5fa-4d77-da42-6faa4dee6a3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>prompt</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>documents</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>More and more people use computers  but not ev...</td>\n",
       "      <td>people use computer not everyone agrees benefi...</td>\n",
       "      <td>[people, use, computer, not, everyone, agrees,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in the Libraries\\n\"All of us can th...</td>\n",
       "      <td>Censorship in the Libraries  All of us can thi...</td>\n",
       "      <td>censorship library u think book hope none chil...</td>\n",
       "      <td>[censorship, library, u, think, book, hope, no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>Write about patience  Being patient means that...</td>\n",
       "      <td>write patience patient mean understanding tole...</td>\n",
       "      <td>[write, patience, patient, mean, understanding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>We all understand the benefits of laughter. Fo...</td>\n",
       "      <td>We all understand the benefits of laughter  Fo...</td>\n",
       "      <td>understand benefit laughter example someone sa...</td>\n",
       "      <td>[understand, benefit, laughter, example, someo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             prompt  \\\n",
       "1          1  More and more people use computers, but not ev...   \n",
       "2          2  Censorship in the Libraries\\n\"All of us can th...   \n",
       "7          7  Write about patience. Being patient means that...   \n",
       "8          8  We all understand the benefits of laughter. Fo...   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "1  More and more people use computers  but not ev...   \n",
       "2  Censorship in the Libraries  All of us can thi...   \n",
       "7  Write about patience  Being patient means that...   \n",
       "8  We all understand the benefits of laughter  Fo...   \n",
       "\n",
       "                                           documents  \\\n",
       "1  people use computer not everyone agrees benefi...   \n",
       "2  censorship library u think book hope none chil...   \n",
       "7  write patience patient mean understanding tole...   \n",
       "8  understand benefit laughter example someone sa...   \n",
       "\n",
       "                                              tokens  \n",
       "1  [people, use, computer, not, everyone, agrees,...  \n",
       "2  [censorship, library, u, think, book, hope, no...  \n",
       "7  [write, patience, patient, mean, understanding...  \n",
       "8  [understand, benefit, laughter, example, someo...  "
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Tv7IJE7YX5_"
   },
   "outputs": [],
   "source": [
    "def get_synonyms(tokens):\n",
    "    synonyms = set()\n",
    "    for word in tokens:\n",
    "        synset = nltk.wordnet.wordnet.synsets(word)\n",
    "        for ss in synset:\n",
    "            for swords in ss.lemma_names():\n",
    "                synonyms.add(swords.lower())\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z8dkx7wMYX6C"
   },
   "outputs": [],
   "source": [
    "essay_prompt_df['synonyms'] = essay_prompt_df['tokens'].apply(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R5NRpLYkYX6D",
    "outputId": "4ccd7d23-7a88-4f2d-8782-b339e1adcc62"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>prompt</th>\n",
       "      <th>clean_prompt</th>\n",
       "      <th>documents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>More and more people use computers, but not ev...</td>\n",
       "      <td>More and more people use computers  but not ev...</td>\n",
       "      <td>people use computer not everyone agrees benefi...</td>\n",
       "      <td>[people, use, computer, not, everyone, agrees,...</td>\n",
       "      <td>[spending, family_line, rise, sing, yet, upgra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Censorship in the Libraries\\n\"All of us can th...</td>\n",
       "      <td>Censorship in the Libraries  All of us can thi...</td>\n",
       "      <td>censorship library u think book hope none chil...</td>\n",
       "      <td>[censorship, library, u, think, book, hope, no...</td>\n",
       "      <td>[argumentation, bump, exploit, polish_off, exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Write about patience. Being patient means that...</td>\n",
       "      <td>Write about patience  Being patient means that...</td>\n",
       "      <td>write patience patient mean understanding tole...</td>\n",
       "      <td>[write, patience, patient, mean, understanding...</td>\n",
       "      <td>[tight, mean_value, bonk, make_out, surveil, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>We all understand the benefits of laughter. Fo...</td>\n",
       "      <td>We all understand the benefits of laughter  Fo...</td>\n",
       "      <td>understand benefit laughter example someone sa...</td>\n",
       "      <td>[understand, benefit, laughter, example, someo...</td>\n",
       "      <td>[straight, allege, divide, aforesaid, mass, in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             prompt  \\\n",
       "1          1  More and more people use computers, but not ev...   \n",
       "2          2  Censorship in the Libraries\\n\"All of us can th...   \n",
       "7          7  Write about patience. Being patient means that...   \n",
       "8          8  We all understand the benefits of laughter. Fo...   \n",
       "\n",
       "                                        clean_prompt  \\\n",
       "1  More and more people use computers  but not ev...   \n",
       "2  Censorship in the Libraries  All of us can thi...   \n",
       "7  Write about patience  Being patient means that...   \n",
       "8  We all understand the benefits of laughter  Fo...   \n",
       "\n",
       "                                           documents  \\\n",
       "1  people use computer not everyone agrees benefi...   \n",
       "2  censorship library u think book hope none chil...   \n",
       "7  write patience patient mean understanding tole...   \n",
       "8  understand benefit laughter example someone sa...   \n",
       "\n",
       "                                              tokens  \\\n",
       "1  [people, use, computer, not, everyone, agrees,...   \n",
       "2  [censorship, library, u, think, book, hope, no...   \n",
       "7  [write, patience, patient, mean, understanding...   \n",
       "8  [understand, benefit, laughter, example, someo...   \n",
       "\n",
       "                                            synonyms  \n",
       "1  [spending, family_line, rise, sing, yet, upgra...  \n",
       "2  [argumentation, bump, exploit, polish_off, exa...  \n",
       "7  [tight, mean_value, bonk, make_out, surveil, b...  \n",
       "8  [straight, allege, divide, aforesaid, mass, in...  "
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_prompt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4Qm-ZzV2YX6F"
   },
   "outputs": [],
   "source": [
    "# essay_prompt_df.to_pickle('essay_prompt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWEaSDNJYX6H"
   },
   "outputs": [],
   "source": [
    "essay_prompt_df = pd.read_pickle('essay_prompt_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8JF_uc3CYX6K"
   },
   "outputs": [],
   "source": [
    "synonyms_overlap = []\n",
    "synonyms_overlap_prop = []\n",
    "prompt_overlap = []\n",
    "prompt_overlap_prop = []\n",
    "\n",
    "for i in range(len(persuasive_essay)):    \n",
    "    essay_set = persuasive_essay['essay_set'][i]\n",
    "    essay_tokens = persuasive_essay['corrected_tokens'][i]\n",
    "    prompt_tokens = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'tokens'][essay_set]\n",
    "    synonyms = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "    synonyms_overlap_temp = [word for word in essay_tokens if word in synonyms]\n",
    "    prompt_overlap_temp = [word for word in essay_tokens if word in prompt_tokens]\n",
    "    \n",
    "    synonyms_overlap.append(len(synonyms_overlap_temp))\n",
    "    synonyms_overlap_prop.append(len(synonyms_overlap_temp)/(len(essay_tokens)+1))\n",
    "    prompt_overlap.append(len(prompt_overlap_temp))\n",
    "    prompt_overlap_prop.append(len(prompt_overlap_temp)/(len(essay_tokens)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8VxXamLYX6N",
    "outputId": "a32d8a6b-aac0-4fd7-d40e-527f4c743103"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "persuasive_essay['syn_overlap'] = synonyms_overlap\n",
    "persuasive_essay['syn_overlap_prop'] = synonyms_overlap_prop\n",
    "persuasive_essay['prompt_overlap'] = prompt_overlap\n",
    "persuasive_essay['prompt_overlap_prop'] = prompt_overlap_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IE7QgH0iYX6P",
    "outputId": "c469fa21-1d28-420e-e0c3-4b38edd5aec1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>syn_overlap_prop</th>\n",
       "      <th>prompt_overlap</th>\n",
       "      <th>prompt_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>46</td>\n",
       "      <td>0.277108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>[Dear, I, believe, that, using, computers, wil...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>39</td>\n",
       "      <td>0.179724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>[Dear, More, and, more, people, use, computers...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>62</td>\n",
       "      <td>0.473282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>0.311355</td>\n",
       "      <td>55</td>\n",
       "      <td>0.201465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>51</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [Dear, local, newspaper, I, think, effects, co...   \n",
       "1  [Dear, I, believe, that, using, computers, wil...   \n",
       "2  [Dear, More, and, more, people, use, computers...   \n",
       "3  [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4  [Dear, I, know, having, computers, has, a, pos...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [Dear local newspaper, I think effects compute...         344          16   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...         413          20   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...         276          14   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...         488          27   \n",
       "4  [Dear @LOCATION1, I know having computers has ...         469          30   \n",
       "\n",
       "   spell_err         ...          noun_count verb_count adv_count  adj_count  \\\n",
       "0         11         ...                  78         37        15         28   \n",
       "1         16         ...                 103         55        10         24   \n",
       "2          2         ...                  74         31         4         18   \n",
       "3         24         ...                 134         53        24         45   \n",
       "4         13         ...                 117         40        11         27   \n",
       "\n",
       "   readability_score  unique_word_ratio  syn_overlap  syn_overlap_prop  \\\n",
       "0              74.02           0.618182           59          0.355422   \n",
       "1              67.08           0.569444           56          0.258065   \n",
       "2              68.20           0.646154           70          0.534351   \n",
       "3              53.34           0.584559           85          0.311355   \n",
       "4              72.66           0.531818           62          0.280543   \n",
       "\n",
       "   prompt_overlap  prompt_overlap_prop  \n",
       "0              46             0.277108  \n",
       "1              39             0.179724  \n",
       "2              62             0.473282  \n",
       "3              55             0.201465  \n",
       "4              51             0.230769  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ngR-8qShYX6R"
   },
   "outputs": [],
   "source": [
    "# persuasive_essay.to_pickle('persuasive_essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSiHDesuYX6T"
   },
   "outputs": [],
   "source": [
    "persuasive_essay = pd.read_pickle('persuasive_essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1737,
     "status": "ok",
     "timestamp": 1587230048024,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "nVAlbzZ9YX6V",
    "outputId": "242da006-3d10-4b2c-c143-73ce0cabb749"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>syn_overlap_prop</th>\n",
       "      <th>prompt_overlap</th>\n",
       "      <th>prompt_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear local newspaper  I think effects computer...</td>\n",
       "      <td>[Dear, local, newspaper, I, think, effects, co...</td>\n",
       "      <td>[Dear local newspaper, I think effects compute...</td>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>0.355422</td>\n",
       "      <td>46</td>\n",
       "      <td>0.277108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "      <td>Dear     I believe that using computers will b...</td>\n",
       "      <td>[Dear, I, believe, that, using, computers, wil...</td>\n",
       "      <td>[Dear @CAPS1 @CAPS2, I believe that using comp...</td>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>39</td>\n",
       "      <td>0.179724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "      <td>Dear        More and more people use computers...</td>\n",
       "      <td>[Dear, More, and, more, people, use, computers...</td>\n",
       "      <td>[Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...</td>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>62</td>\n",
       "      <td>0.473282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "      <td>Dear Local Newspaper    I have found that many...</td>\n",
       "      <td>[Dear, Local, Newspaper, I, have, found, that,...</td>\n",
       "      <td>[Dear Local Newspaper, @CAPS1 I have found tha...</td>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>0.311355</td>\n",
       "      <td>55</td>\n",
       "      <td>0.201465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "      <td>Dear   I know having computers has a positive ...</td>\n",
       "      <td>[Dear, I, know, having, computers, has, a, pos...</td>\n",
       "      <td>[Dear @LOCATION1, I know having computers has ...</td>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>0.280543</td>\n",
       "      <td>51</td>\n",
       "      <td>0.230769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              8  Dear local newspaper  I think effects computer...   \n",
       "1              9  Dear     I believe that using computers will b...   \n",
       "2              7  Dear        More and more people use computers...   \n",
       "3             10  Dear Local Newspaper    I have found that many...   \n",
       "4              8  Dear   I know having computers has a positive ...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [Dear, local, newspaper, I, think, effects, co...   \n",
       "1  [Dear, I, believe, that, using, computers, wil...   \n",
       "2  [Dear, More, and, more, people, use, computers...   \n",
       "3  [Dear, Local, Newspaper, I, have, found, that,...   \n",
       "4  [Dear, I, know, having, computers, has, a, pos...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [Dear local newspaper, I think effects compute...         344          16   \n",
       "1  [Dear @CAPS1 @CAPS2, I believe that using comp...         413          20   \n",
       "2  [Dear, @CAPS1 @CAPS2 @CAPS3 More and more peop...         276          14   \n",
       "3  [Dear Local Newspaper, @CAPS1 I have found tha...         488          27   \n",
       "4  [Dear @LOCATION1, I know having computers has ...         469          30   \n",
       "\n",
       "   spell_err         ...          noun_count verb_count adv_count  adj_count  \\\n",
       "0         11         ...                  78         37        15         28   \n",
       "1         16         ...                 103         55        10         24   \n",
       "2          2         ...                  74         31         4         18   \n",
       "3         24         ...                 134         53        24         45   \n",
       "4         13         ...                 117         40        11         27   \n",
       "\n",
       "   readability_score  unique_word_ratio  syn_overlap  syn_overlap_prop  \\\n",
       "0              74.02           0.618182           59          0.355422   \n",
       "1              67.08           0.569444           56          0.258065   \n",
       "2              68.20           0.646154           70          0.534351   \n",
       "3              53.34           0.584559           85          0.311355   \n",
       "4              72.66           0.531818           62          0.280543   \n",
       "\n",
       "   prompt_overlap  prompt_overlap_prop  \n",
       "0              46             0.277108  \n",
       "1              39             0.179724  \n",
       "2              62             0.473282  \n",
       "3              55             0.201465  \n",
       "4              51             0.230769  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persuasive_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4FY37aZYX6X"
   },
   "outputs": [],
   "source": [
    "essay_set1 = persuasive_essay[persuasive_essay['essay_set']==1]\n",
    "essay_set2 = persuasive_essay[persuasive_essay['essay_set']==2]\n",
    "essay_set7 = persuasive_essay[persuasive_essay['essay_set']==7]\n",
    "essay_set8 = persuasive_essay[persuasive_essay['essay_set']==8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6AnCJQpYX6Z"
   },
   "outputs": [],
   "source": [
    "# essay_set1.to_pickle('essay_set1')\n",
    "# essay_set2.to_pickle('essay_set2')\n",
    "# essay_set7.to_pickle('essay_set7')\n",
    "# essay_set8.to_pickle('essay_set8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZqSht1RYX6b"
   },
   "outputs": [],
   "source": [
    "source_essay = clean_df[(clean_df['essay_set']== 3) | (clean_df['essay_set']== 4) | (clean_df['essay_set']== 5) | (clean_df['essay_set']== 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0O5emd6iYX6e"
   },
   "outputs": [],
   "source": [
    "source_essay.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-JY94I07YX6h",
    "outputId": "c3a5942d-699f-4dc7-aa00-ad4f080ee208"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>corrected_essay</th>\n",
       "      <th>essay_documents</th>\n",
       "      <th>corrected_tokens</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>16629</td>\n",
       "      <td>6</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>[The, one, obstacle, the, builders, had, when,...</td>\n",
       "      <td>[The one obstacle the builders had when trying...</td>\n",
       "      <td>152</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>The one obstacle the builders had when trying ...</td>\n",
       "      <td>one obstacle builder trying build building not...</td>\n",
       "      <td>[one, obstacle, builder, trying, build, buildi...</td>\n",
       "      <td>36</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>77.27</td>\n",
       "      <td>0.706667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>16630</td>\n",
       "      <td>6</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>2</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>[Some, of, the, problems, with, the, construct...</td>\n",
       "      <td>[Some of the problems with the constructing of...</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Some of the problems with the constructing of ...</td>\n",
       "      <td>problem constructing docking dirigible natural...</td>\n",
       "      <td>[problem, constructing, docking, dirigible, na...</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>57.30</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>16631</td>\n",
       "      <td>6</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>3</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>[The, builders, of, the, Empire, State, buildi...</td>\n",
       "      <td>[The builders of the Empire State building fac...</td>\n",
       "      <td>105</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>The builders of the Empire State building face...</td>\n",
       "      <td>builder empire state building faced obstacle a...</td>\n",
       "      <td>[builder, empire, state, building, faced, obst...</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>16632</td>\n",
       "      <td>6</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>2</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>[The, obstacles, the, builders, of, the, Empir...</td>\n",
       "      <td>[The obstacles the builders of the Empire Stat...</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>The obstacles the builders of the Empire State...</td>\n",
       "      <td>obstacle builder empire state building could n...</td>\n",
       "      <td>[obstacle, builder, empire, state, building, c...</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>53.89</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>16633</td>\n",
       "      <td>6</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>2</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>[You, want, me, to, tell, you, what, they, had...</td>\n",
       "      <td>[You want me to tell you what they had to go t...</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>You want me to tell you what they had to go th...</td>\n",
       "      <td>want tell go attempt allow dirigible dock well...</td>\n",
       "      <td>[want, tell, go, attempt, allow, dirigible, do...</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>64.78</td>\n",
       "      <td>0.632911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      essay_id  essay_set                                              essay  \\\n",
       "7096     16629          6  The one obstacle the builders had when trying ...   \n",
       "7097     16630          6  Some of the problems with the constructing of ...   \n",
       "7098     16631          6  The builders of the Empire State building face...   \n",
       "7099     16632          6  The obstacles the builders of the Empire State...   \n",
       "7100     16633          6  You want me to tell you what they had to go th...   \n",
       "\n",
       "      domain1_score                                        clean_essay  \\\n",
       "7096              0  The one obstacle the builders had when trying ...   \n",
       "7097              2  Some of the problems with the constructing of ...   \n",
       "7098              3  The builders of the Empire State building face...   \n",
       "7099              2  The obstacles the builders of the Empire State...   \n",
       "7100              2  You want me to tell you what they had to go th...   \n",
       "\n",
       "                                            word_tokens  \\\n",
       "7096  [The, one, obstacle, the, builders, had, when,...   \n",
       "7097  [Some, of, the, problems, with, the, construct...   \n",
       "7098  [The, builders, of, the, Empire, State, buildi...   \n",
       "7099  [The, obstacles, the, builders, of, the, Empir...   \n",
       "7100  [You, want, me, to, tell, you, what, they, had...   \n",
       "\n",
       "                                            sent_tokens  word_count  \\\n",
       "7096  [The one obstacle the builders had when trying...         152   \n",
       "7097  [Some of the problems with the constructing of...          66   \n",
       "7098  [The builders of the Empire State building fac...         105   \n",
       "7099  [The obstacles the builders of the Empire Stat...          68   \n",
       "7100  [You want me to tell you what they had to go t...         157   \n",
       "\n",
       "      sent_count  spell_err  \\\n",
       "7096           8         10   \n",
       "7097           3          0   \n",
       "7098           5          1   \n",
       "7099           2          1   \n",
       "7100           9          2   \n",
       "\n",
       "                                        corrected_essay  \\\n",
       "7096  The one obstacle the builders had when trying ...   \n",
       "7097  Some of the problems with the constructing of ...   \n",
       "7098  The builders of the Empire State building face...   \n",
       "7099  The obstacles the builders of the Empire State...   \n",
       "7100  You want me to tell you what they had to go th...   \n",
       "\n",
       "                                        essay_documents  \\\n",
       "7096  one obstacle builder trying build building not...   \n",
       "7097  problem constructing docking dirigible natural...   \n",
       "7098  builder empire state building faced obstacle a...   \n",
       "7099  obstacle builder empire state building could n...   \n",
       "7100  want tell go attempt allow dirigible dock well...   \n",
       "\n",
       "                                       corrected_tokens  noun_count  \\\n",
       "7096  [one, obstacle, builder, trying, build, buildi...          36   \n",
       "7097  [problem, constructing, docking, dirigible, na...          13   \n",
       "7098  [builder, empire, state, building, faced, obst...          30   \n",
       "7099  [obstacle, builder, empire, state, building, c...          18   \n",
       "7100  [want, tell, go, attempt, allow, dirigible, do...          33   \n",
       "\n",
       "      verb_count  adv_count  adj_count  readability_score  unique_word_ratio  \n",
       "7096          13         10          9              77.27           0.706667  \n",
       "7097           8          4         11              57.30           0.925000  \n",
       "7098           8          5          9              58.62           0.814815  \n",
       "7099           7          3          5              53.89           0.810811  \n",
       "7100          19          4         14              64.78           0.632911  "
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wqeTgXI1YX6k"
   },
   "outputs": [],
   "source": [
    "source3 = open(\"source/Source3.txt\",'r',encoding='utf-8')\n",
    "source3 = source3.read()\n",
    "source4 = open(\"source/Source4.txt\",'r',encoding='utf-8')\n",
    "source4 = source4.read()\n",
    "source5 = open(\"source/Source5.txt\",'r',encoding='utf-8')\n",
    "source5 = source5.read()\n",
    "source6 = open(\"source/Source6.txt\",'r',encoding='utf-8')\n",
    "source6 = source6.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Go0QyU5YX6m"
   },
   "outputs": [],
   "source": [
    "source_set = [3,4,5,6]\n",
    "source = [source3,source4,source5,source6]\n",
    "essay_source_df = pd.DataFrame({'essay_set':source_set,'source':source},index=source_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBQbv9CjYX6p"
   },
   "outputs": [],
   "source": [
    "essay_source_df['clean_source'] = essay_source_df['source'].apply(remove_special_char)\n",
    "essay_source_df['documents'] = essay_source_df['clean_source'].apply(create_documents)\n",
    "essay_source_df['tokens'] = essay_source_df['documents'].apply(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzf38UJpYX6t"
   },
   "outputs": [],
   "source": [
    "def nouns_and_verbs_pos(tokens):\n",
    "    word_pos = nltk.pos_tag(tokens)\n",
    "    nouns_and_verbs = set()\n",
    "    for pos in word_pos:\n",
    "        if (pos[1][0] == 'V') | (pos[1][0] == 'N'):\n",
    "            nouns_and_verbs.add(pos[0])\n",
    "    return list(nouns_and_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rM2o17EsYX6u"
   },
   "outputs": [],
   "source": [
    "essay_source_df['pos(nouns & verbs)'] = essay_source_df['tokens'].apply(nouns_and_verbs_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3AecDTg5YX6w"
   },
   "outputs": [],
   "source": [
    "essay_source_df['synonyms'] = essay_source_df['pos(nouns & verbs)'].apply(get_synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Pce51yFYX6y",
    "outputId": "e14c4a9a-cfde-4900-fb89-95f10f838a60"
   },
   "outputs": [],
   "source": [
    "# essay_source_df.to_pickle('essay_source_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "essay_source_df = pd.read_pickle('essay_source_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_set</th>\n",
       "      <th>source</th>\n",
       "      <th>clean_source</th>\n",
       "      <th>documents</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos(nouns &amp; verbs)</th>\n",
       "      <th>synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ROUGH ROAD AHEAD: Do Not Exceed Posted Speed L...</td>\n",
       "      <td>ROUGH ROAD AHEAD  Do Not Exceed Posted Speed L...</td>\n",
       "      <td>rough road ahead not exceed posted speed limit...</td>\n",
       "      <td>[rough, road, ahead, not, exceed, posted, spee...</td>\n",
       "      <td>[mind, lodge, wisdom, replaced, depleting, riv...</td>\n",
       "      <td>[guidance, bump_off, libra_the_balance, smoky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Winter Hibiscus by Minfong Ho\\nSaeng, a teenag...</td>\n",
       "      <td>Winter Hibiscus by Minfong Ho Saeng  a teenage...</td>\n",
       "      <td>winter hibiscus minfong ho saeng teenage girl ...</td>\n",
       "      <td>[winter, hibiscus, minfong, ho, saeng, teenage...</td>\n",
       "      <td>[floating, gallo, laio, closed, delicate, aske...</td>\n",
       "      <td>[hark_back, luxuriant, depart, dapple, crapper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Narciso Rodriguez\\nfrom Home: The Blueprints o...</td>\n",
       "      <td>Narciso Rodriguez from Home  The Blueprints of...</td>\n",
       "      <td>narciso rodriguez home blueprint life parent o...</td>\n",
       "      <td>[narciso, rodriguez, home, blueprint, life, pa...</td>\n",
       "      <td>[jersey, child, blueprint, day, loved, aunt, d...</td>\n",
       "      <td>[prolonged, depart, motivation, smell, mold, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The Mooring Mast\\nby Marcia Amidon LÃ¼sted\\nWhe...</td>\n",
       "      <td>The Mooring Mast by Marcia Amidon L sted When ...</td>\n",
       "      <td>mooring mast marcia amidon l sted empire state...</td>\n",
       "      <td>[mooring, mast, marcia, amidon, l, sted, empir...</td>\n",
       "      <td>[inc, machinery, rope, construction, amidon, m...</td>\n",
       "      <td>[landing_place, depart, chieftain, mold, accen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_set                                             source  \\\n",
       "3          3  ROUGH ROAD AHEAD: Do Not Exceed Posted Speed L...   \n",
       "4          4  Winter Hibiscus by Minfong Ho\\nSaeng, a teenag...   \n",
       "5          5  Narciso Rodriguez\\nfrom Home: The Blueprints o...   \n",
       "6          6  The Mooring Mast\\nby Marcia Amidon LÃ¼sted\\nWhe...   \n",
       "\n",
       "                                        clean_source  \\\n",
       "3  ROUGH ROAD AHEAD  Do Not Exceed Posted Speed L...   \n",
       "4  Winter Hibiscus by Minfong Ho Saeng  a teenage...   \n",
       "5  Narciso Rodriguez from Home  The Blueprints of...   \n",
       "6  The Mooring Mast by Marcia Amidon L sted When ...   \n",
       "\n",
       "                                           documents  \\\n",
       "3  rough road ahead not exceed posted speed limit...   \n",
       "4  winter hibiscus minfong ho saeng teenage girl ...   \n",
       "5  narciso rodriguez home blueprint life parent o...   \n",
       "6  mooring mast marcia amidon l sted empire state...   \n",
       "\n",
       "                                              tokens  \\\n",
       "3  [rough, road, ahead, not, exceed, posted, spee...   \n",
       "4  [winter, hibiscus, minfong, ho, saeng, teenage...   \n",
       "5  [narciso, rodriguez, home, blueprint, life, pa...   \n",
       "6  [mooring, mast, marcia, amidon, l, sted, empir...   \n",
       "\n",
       "                                  pos(nouns & verbs)  \\\n",
       "3  [mind, lodge, wisdom, replaced, depleting, riv...   \n",
       "4  [floating, gallo, laio, closed, delicate, aske...   \n",
       "5  [jersey, child, blueprint, day, loved, aunt, d...   \n",
       "6  [inc, machinery, rope, construction, amidon, m...   \n",
       "\n",
       "                                            synonyms  \n",
       "3  [guidance, bump_off, libra_the_balance, smoky,...  \n",
       "4  [hark_back, luxuriant, depart, dapple, crapper...  \n",
       "5  [prolonged, depart, motivation, smell, mold, s...  \n",
       "6  [landing_place, depart, chieftain, mold, accen...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xbpt2PLZYX6z",
    "outputId": "2fd9962d-54a9-4729-fd2e-a97e39bf38e7"
   },
   "outputs": [],
   "source": [
    "synonyms_overlap = []\n",
    "synonyms_overlap_prop = []\n",
    "\n",
    "source_overlap = []\n",
    "source_overlap_prop = []\n",
    "\n",
    "for i in range(len(source_essay)):\n",
    "    \n",
    "    essay_set = source_essay['essay_set'][i]\n",
    "    essay_tokens = source_essay['corrected_tokens'][i]\n",
    "    \n",
    "    source_tokens = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'pos(nouns & verbs)'][essay_set]\n",
    "    source_overlap_temp = [word for word in essay_tokens if word in source_tokens]\n",
    "    source_overlap.append(len(source_overlap_temp))\n",
    "    source_overlap_prop.append(len(source_overlap_temp)/(len(essay_tokens)+1))\n",
    "\n",
    "    synonyms = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "    synonyms_overlap_temp = [word for word in essay_tokens if word in synonyms]    \n",
    "    synonyms_overlap.append(len(synonyms_overlap_temp))\n",
    "    synonyms_overlap_prop.append(len(synonyms_overlap_temp)/(len(essay_tokens)+1))\n",
    "\n",
    "source_essay['source_overlap'] = source_overlap\n",
    "source_essay['source_overlap_prop'] = source_overlap_prop\n",
    "source_essay['synonyms_overlap'] = synonyms_overlap\n",
    "source_essay['synonyms_overlap_prop'] = synonyms_overlap_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>source_overlap</th>\n",
       "      <th>source_overlap_prop</th>\n",
       "      <th>synonyms_overlap</th>\n",
       "      <th>synonyms_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>[The, features, of, the, setting, affect, the,...</td>\n",
       "      <td>[The features of the setting affect the cyclis...</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>71.14</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>14</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>[The, features, of, the, setting, affected, th...</td>\n",
       "      <td>[The features of the setting affected the cycl...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>62.92</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>40</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1</td>\n",
       "      <td>Everyone travels to unfamiliar places  Sometim...</td>\n",
       "      <td>[Everyone, travels, to, unfamiliar, places, So...</td>\n",
       "      <td>[Everyone travels to unfamiliar places., Somet...</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>72.36</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>19</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5981</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>[I, believe, the, features, of, the, cyclist, ...</td>\n",
       "      <td>[I believe the features of the cyclist affecte...</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>10</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>15</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>[The, setting, effects, the, cyclist, because,...</td>\n",
       "      <td>[The setting effects the cyclist because of th...</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>51.89</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>19</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>28</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      5978          3  The features of the setting affect the cyclist...   \n",
       "1      5979          3  The features of the setting affected the cycli...   \n",
       "2      5980          3  Everyone travels to unfamiliar places. Sometim...   \n",
       "3      5981          3  I believe the features of the cyclist affected...   \n",
       "4      5982          3  The setting effects the cyclist because of the...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              1  The features of the setting affect the cyclist...   \n",
       "1              2  The features of the setting affected the cycli...   \n",
       "2              1  Everyone travels to unfamiliar places  Sometim...   \n",
       "3              1  I believe the features of the cyclist affected...   \n",
       "4              2  The setting effects the cyclist because of the...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [The, features, of, the, setting, affect, the,...   \n",
       "1  [The, features, of, the, setting, affected, th...   \n",
       "2  [Everyone, travels, to, unfamiliar, places, So...   \n",
       "3  [I, believe, the, features, of, the, cyclist, ...   \n",
       "4  [The, setting, effects, the, cyclist, because,...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [The features of the setting affect the cyclis...          51           3   \n",
       "1  [The features of the setting affected the cycl...         174          12   \n",
       "2  [Everyone travels to unfamiliar places., Somet...          96           8   \n",
       "3  [I believe the features of the cyclist affecte...          87           3   \n",
       "4  [The setting effects the cyclist because of th...         133           3   \n",
       "\n",
       "   spell_err          ...           noun_count verb_count adv_count  \\\n",
       "0          1          ...                   11          5         0   \n",
       "1         11          ...                   39         15         6   \n",
       "2          0          ...                   19         12         7   \n",
       "3         10          ...                   15          9         3   \n",
       "4          8          ...                   27         16         3   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  source_overlap  \\\n",
       "0          5              71.14           0.714286               8   \n",
       "1         17              62.92           0.800000              41   \n",
       "2          9              72.36           0.816327              19   \n",
       "3         12              53.21           0.951220              10   \n",
       "4         14              51.89           0.661538              19   \n",
       "\n",
       "   source_overlap_prop  synonyms_overlap  synonyms_overlap_prop  \n",
       "0             0.363636                14               0.636364  \n",
       "1             0.476744                40               0.465116  \n",
       "2             0.380000                24               0.480000  \n",
       "3             0.238095                15               0.357143  \n",
       "4             0.287879                28               0.424242  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zaS34plkYX61",
    "outputId": "dfdd7ac0-5ac6-4fe4-df35-d99210889826"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>source_overlap</th>\n",
       "      <th>source_overlap_prop</th>\n",
       "      <th>synonyms_overlap</th>\n",
       "      <th>synonyms_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>[The, features, of, the, setting, affect, the,...</td>\n",
       "      <td>[The features of the setting affect the cyclis...</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>71.14</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>14</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>[The, features, of, the, setting, affected, th...</td>\n",
       "      <td>[The features of the setting affected the cycl...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>62.92</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>40</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1</td>\n",
       "      <td>Everyone travels to unfamiliar places  Sometim...</td>\n",
       "      <td>[Everyone, travels, to, unfamiliar, places, So...</td>\n",
       "      <td>[Everyone travels to unfamiliar places., Somet...</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>72.36</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>19</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5981</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>[I, believe, the, features, of, the, cyclist, ...</td>\n",
       "      <td>[I believe the features of the cyclist affecte...</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>10</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>15</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>[The, setting, effects, the, cyclist, because,...</td>\n",
       "      <td>[The setting effects the cyclist because of th...</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>51.89</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>19</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>28</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      5978          3  The features of the setting affect the cyclist...   \n",
       "1      5979          3  The features of the setting affected the cycli...   \n",
       "2      5980          3  Everyone travels to unfamiliar places. Sometim...   \n",
       "3      5981          3  I believe the features of the cyclist affected...   \n",
       "4      5982          3  The setting effects the cyclist because of the...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              1  The features of the setting affect the cyclist...   \n",
       "1              2  The features of the setting affected the cycli...   \n",
       "2              1  Everyone travels to unfamiliar places  Sometim...   \n",
       "3              1  I believe the features of the cyclist affected...   \n",
       "4              2  The setting effects the cyclist because of the...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [The, features, of, the, setting, affect, the,...   \n",
       "1  [The, features, of, the, setting, affected, th...   \n",
       "2  [Everyone, travels, to, unfamiliar, places, So...   \n",
       "3  [I, believe, the, features, of, the, cyclist, ...   \n",
       "4  [The, setting, effects, the, cyclist, because,...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [The features of the setting affect the cyclis...          51           3   \n",
       "1  [The features of the setting affected the cycl...         174          12   \n",
       "2  [Everyone travels to unfamiliar places., Somet...          96           8   \n",
       "3  [I believe the features of the cyclist affecte...          87           3   \n",
       "4  [The setting effects the cyclist because of th...         133           3   \n",
       "\n",
       "   spell_err          ...           noun_count verb_count adv_count  \\\n",
       "0          1          ...                   11          5         0   \n",
       "1         11          ...                   39         15         6   \n",
       "2          0          ...                   19         12         7   \n",
       "3         10          ...                   15          9         3   \n",
       "4          8          ...                   27         16         3   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  source_overlap  \\\n",
       "0          5              71.14           0.714286               8   \n",
       "1         17              62.92           0.800000              41   \n",
       "2          9              72.36           0.816327              19   \n",
       "3         12              53.21           0.951220              10   \n",
       "4         14              51.89           0.661538              19   \n",
       "\n",
       "   source_overlap_prop  synonyms_overlap  synonyms_overlap_prop  \n",
       "0             0.363636                14               0.636364  \n",
       "1             0.476744                40               0.465116  \n",
       "2             0.380000                24               0.480000  \n",
       "3             0.238095                15               0.357143  \n",
       "4             0.287879                28               0.424242  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkX2980tYX62"
   },
   "outputs": [],
   "source": [
    "# source_essay.to_pickle('source_essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yigp0SGmYX64"
   },
   "outputs": [],
   "source": [
    "source_essay = pd.read_pickle('source_essay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n689StgsYX65",
    "outputId": "eb0b90b7-0491-42dc-80a5-703c0d70a215"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "      <th>clean_essay</th>\n",
       "      <th>word_tokens</th>\n",
       "      <th>sent_tokens</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>...</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>source_overlap</th>\n",
       "      <th>source_overlap_prop</th>\n",
       "      <th>synonyms_overlap</th>\n",
       "      <th>synonyms_overlap_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5978</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>1</td>\n",
       "      <td>The features of the setting affect the cyclist...</td>\n",
       "      <td>[The, features, of, the, setting, affect, the,...</td>\n",
       "      <td>[The features of the setting affect the cyclis...</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>71.14</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>8</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>14</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5979</td>\n",
       "      <td>3</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>2</td>\n",
       "      <td>The features of the setting affected the cycli...</td>\n",
       "      <td>[The, features, of, the, setting, affected, th...</td>\n",
       "      <td>[The features of the setting affected the cycl...</td>\n",
       "      <td>174</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>62.92</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>41</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>40</td>\n",
       "      <td>0.465116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5980</td>\n",
       "      <td>3</td>\n",
       "      <td>Everyone travels to unfamiliar places. Sometim...</td>\n",
       "      <td>1</td>\n",
       "      <td>Everyone travels to unfamiliar places  Sometim...</td>\n",
       "      <td>[Everyone, travels, to, unfamiliar, places, So...</td>\n",
       "      <td>[Everyone travels to unfamiliar places., Somet...</td>\n",
       "      <td>96</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>72.36</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>19</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5981</td>\n",
       "      <td>3</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe the features of the cyclist affected...</td>\n",
       "      <td>[I, believe, the, features, of, the, cyclist, ...</td>\n",
       "      <td>[I believe the features of the cyclist affecte...</td>\n",
       "      <td>87</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>53.21</td>\n",
       "      <td>0.951220</td>\n",
       "      <td>10</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>15</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5982</td>\n",
       "      <td>3</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>The setting effects the cyclist because of the...</td>\n",
       "      <td>[The, setting, effects, the, cyclist, because,...</td>\n",
       "      <td>[The setting effects the cyclist because of th...</td>\n",
       "      <td>133</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>51.89</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>19</td>\n",
       "      <td>0.287879</td>\n",
       "      <td>28</td>\n",
       "      <td>0.424242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      5978          3  The features of the setting affect the cyclist...   \n",
       "1      5979          3  The features of the setting affected the cycli...   \n",
       "2      5980          3  Everyone travels to unfamiliar places. Sometim...   \n",
       "3      5981          3  I believe the features of the cyclist affected...   \n",
       "4      5982          3  The setting effects the cyclist because of the...   \n",
       "\n",
       "   domain1_score                                        clean_essay  \\\n",
       "0              1  The features of the setting affect the cyclist...   \n",
       "1              2  The features of the setting affected the cycli...   \n",
       "2              1  Everyone travels to unfamiliar places  Sometim...   \n",
       "3              1  I believe the features of the cyclist affected...   \n",
       "4              2  The setting effects the cyclist because of the...   \n",
       "\n",
       "                                         word_tokens  \\\n",
       "0  [The, features, of, the, setting, affect, the,...   \n",
       "1  [The, features, of, the, setting, affected, th...   \n",
       "2  [Everyone, travels, to, unfamiliar, places, So...   \n",
       "3  [I, believe, the, features, of, the, cyclist, ...   \n",
       "4  [The, setting, effects, the, cyclist, because,...   \n",
       "\n",
       "                                         sent_tokens  word_count  sent_count  \\\n",
       "0  [The features of the setting affect the cyclis...          51           3   \n",
       "1  [The features of the setting affected the cycl...         174          12   \n",
       "2  [Everyone travels to unfamiliar places., Somet...          96           8   \n",
       "3  [I believe the features of the cyclist affecte...          87           3   \n",
       "4  [The setting effects the cyclist because of th...         133           3   \n",
       "\n",
       "   spell_err          ...           noun_count verb_count adv_count  \\\n",
       "0          1          ...                   11          5         0   \n",
       "1         11          ...                   39         15         6   \n",
       "2          0          ...                   19         12         7   \n",
       "3         10          ...                   15          9         3   \n",
       "4          8          ...                   27         16         3   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  source_overlap  \\\n",
       "0          5              71.14           0.714286               8   \n",
       "1         17              62.92           0.800000              41   \n",
       "2          9              72.36           0.816327              19   \n",
       "3         12              53.21           0.951220              10   \n",
       "4         14              51.89           0.661538              19   \n",
       "\n",
       "   source_overlap_prop  synonyms_overlap  synonyms_overlap_prop  \n",
       "0             0.363636                14               0.636364  \n",
       "1             0.476744                40               0.465116  \n",
       "2             0.380000                24               0.480000  \n",
       "3             0.238095                15               0.357143  \n",
       "4             0.287879                28               0.424242  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_essay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HVG1ruG1YX66"
   },
   "outputs": [],
   "source": [
    "essay_set3 = source_essay[source_essay['essay_set']==3]\n",
    "essay_set4 = source_essay[source_essay['essay_set']==4]\n",
    "essay_set5 = source_essay[source_essay['essay_set']==5]\n",
    "essay_set6 = source_essay[source_essay['essay_set']==6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OIQyValWYX67"
   },
   "outputs": [],
   "source": [
    "# essay_set3.to_pickle('essay_set3')\n",
    "# essay_set4.to_pickle('essay_set4')\n",
    "# essay_set5.to_pickle('essay_set5')\n",
    "# essay_set6.to_pickle('essay_set6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ICX8uMIYX69"
   },
   "outputs": [],
   "source": [
    "X = essay_set1.drop(['essay_id','essay_set','essay','domain1_score','clean_essay','word_tokens','sent_tokens','corrected_essay','essay_documents','corrected_tokens'],axis=1)\n",
    "y = essay_set1['domain1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1363,
     "status": "ok",
     "timestamp": 1587233201275,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "WWFnUKNTeHO9",
    "outputId": "4f6642ee-6092-4c62-e37b-ea232460b38d"
   },
   "outputs": [],
   "source": [
    "X.reset_index(drop=True,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e8f6z7LaYX6-"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(essay_set1['essay_documents'])\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist() \n",
    "df = pd.DataFrame(denselist, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7362,
     "status": "ok",
     "timestamp": 1587232712198,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "qkSy_frbYX7B",
    "outputId": "175f120a-9c7d-4be3-d3fd-6e28a1de5170"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abd</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abducted</th>\n",
       "      <th>abduction</th>\n",
       "      <th>abe</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zingbobway</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8943 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  abandon  abandoned  abbreviated  abbreviation  abd  abdication  \\\n",
       "0  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "1  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "2  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "3  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "4  0.0      0.0        0.0          0.0           0.0  0.0         0.0   \n",
       "\n",
       "   abducted  abduction  abe  ...   yup  zap  zero  zingbobway      zip  \\\n",
       "0       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "1       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "2       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "3       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.09828   \n",
       "4       0.0        0.0  0.0  ...   0.0  0.0   0.0         0.0  0.00000   \n",
       "\n",
       "   zombie  zone  zoning  zoo  zoom  \n",
       "0     0.0   0.0     0.0  0.0   0.0  \n",
       "1     0.0   0.0     0.0  0.0   0.0  \n",
       "2     0.0   0.0     0.0  0.0   0.0  \n",
       "3     0.0   0.0     0.0  0.0   0.0  \n",
       "4     0.0   0.0     0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 8943 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kzilu3a1YX7C"
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([X,df],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7034,
     "status": "ok",
     "timestamp": 1587232712204,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "2v_fmRLyYX7E",
    "outputId": "ed2e71d3-498d-4174-db58-9e3a40e113ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>zap</th>\n",
       "      <th>zero</th>\n",
       "      <th>zingbobway</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoning</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>344</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>78</td>\n",
       "      <td>37</td>\n",
       "      <td>15</td>\n",
       "      <td>28</td>\n",
       "      <td>74.02</td>\n",
       "      <td>0.618182</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>103</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>67.08</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>68.20</td>\n",
       "      <td>0.646154</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488</td>\n",
       "      <td>27</td>\n",
       "      <td>24</td>\n",
       "      <td>134</td>\n",
       "      <td>53</td>\n",
       "      <td>24</td>\n",
       "      <td>45</td>\n",
       "      <td>53.34</td>\n",
       "      <td>0.584559</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>469</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>117</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>27</td>\n",
       "      <td>72.66</td>\n",
       "      <td>0.531818</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8956 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  sent_count  spell_err  noun_count  verb_count  adv_count  \\\n",
       "0         344          16         11          78          37         15   \n",
       "1         413          20         16         103          55         10   \n",
       "2         276          14          2          74          31          4   \n",
       "3         488          27         24         134          53         24   \n",
       "4         469          30         13         117          40         11   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  syn_overlap  ...   yup  \\\n",
       "0         28              74.02           0.618182           59  ...   0.0   \n",
       "1         24              67.08           0.569444           56  ...   0.0   \n",
       "2         18              68.20           0.646154           70  ...   0.0   \n",
       "3         45              53.34           0.584559           85  ...   0.0   \n",
       "4         27              72.66           0.531818           62  ...   0.0   \n",
       "\n",
       "   zap  zero  zingbobway      zip  zombie  zone  zoning  zoo  zoom  \n",
       "0  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "1  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "2  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "3  0.0   0.0         0.0  0.09828     0.0   0.0     0.0  0.0   0.0  \n",
       "4  0.0   0.0         0.0  0.00000     0.0   0.0     0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 8956 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "daUX0594YX7F"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1325,
     "status": "ok",
     "timestamp": 1587236428368,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "rZsS0foOYX7G",
    "outputId": "8f6b5801-bda2-4606-94e5-0562fa22be1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1248, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EjCGrmv9YX7J"
   },
   "outputs": [],
   "source": [
    "def eval_metrics():\n",
    "    from sklearn import metrics\n",
    "    print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print(\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
    "    print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Cohen\\'s kappa score: %.2f' % metrics.cohen_kappa_score(np.rint(y_pred), y_test,weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_9tbIH5YX7L"
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# GBR=GradientBoostingRegressor()\n",
    "# optimization_dict = {'max_depth': [2,4,6],\n",
    "#                      'n_estimators': [100,200,300,500,1000],\n",
    "#                     'learning_rate':[0.01,0.05,0.1,0.5],\n",
    "#                     'max_features':['auto'],\n",
    "#                     'min_samples_split':[2,4,10,15],\n",
    "#                     'min_samples_leaf':[2,4,10,15]}\n",
    "\n",
    "# gridsearch = GridSearchCV(GBR, optimization_dict, verbose=1)\n",
    "# gridsearch.fit(X_train,y_train)\n",
    "# print(\"best_accuracy:\",gridsearch.best_score_)\n",
    "# print(\"best_parameters:\",gridsearch.best_params_)\n",
    "# print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1132,
     "status": "ok",
     "timestamp": 1587236440732,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "3AKc9BB8YX7M",
    "outputId": "01e7b36a-9a42-43f0-d1d5-c537b4a5d384"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8335976600646973\n",
      "MAE: 0.6298558583748092\n",
      "MSE: 0.6774063453586133\n",
      "RMSE: 0.8230469885484141\n",
      "Cohen's kappa score: 0.83\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "regressor=GradientBoostingRegressor()\n",
    "regressor.fit(X_train,y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(time.time()-start)\n",
    "eval_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_set6.pkl']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(regressor,'model_set6.pkl')\n",
    "joblib.dump(vectorizer,'tfidf_set6.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6pH8UpHfEPU"
   },
   "outputs": [],
   "source": [
    "def create_data(essay,essay_set,essay_prompt_df,essay_source_df):\n",
    "    clean_essay = remove_special_char(essay)\n",
    "    word_tokens = word_tokenizer(clean_essay)\n",
    "    sent_tokens = sent_tokenizer(essay)\n",
    "    word_count = count(word_tokens)\n",
    "    sent_count = count(sent_tokens)\n",
    "    spell_err , corrected_essay = check_spell(word_tokens)\n",
    "    essay_documents = create_documents(corrected_essay)\n",
    "    corrected_tokens = word_tokenizer(essay_documents)\n",
    "    noun_count,verb_count,adv_count,adj_count = pos_count(corrected_tokens)\n",
    "    readability_score = compute_redability(essay)\n",
    "    unique_word_ratio = unique_word_prop(corrected_tokens)\n",
    "    \n",
    "    if essay_set in [1,2,7,8]:\n",
    "        prompt_tokens = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'tokens'][essay_set]\n",
    "        synonyms = essay_prompt_df.loc[essay_prompt_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "        synonyms_overlap_temp = [word for word in corrected_tokens if word in synonyms]\n",
    "        prompt_overlap_temp = [word for word in corrected_tokens if word in prompt_tokens]\n",
    "        synonyms_overlap = (len(synonyms_overlap_temp))\n",
    "        synonyms_overlap_prop = (len(synonyms_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        prompt_overlap = (len(prompt_overlap_temp))\n",
    "        prompt_overlap_prop = (len(prompt_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        X = pd.DataFrame({'word_count' : word_count, 'sent_count' : sent_count, 'spell_err' : spell_err,'noun_count': noun_count,\n",
    "                        'verb_count' : verb_count,'adv_count':adv_count, 'adj_count':adj_count, 'readability_score':readability_score, \n",
    "                        'unique_word_ratio':unique_word_ratio,'syn_overlap':synonyms_overlap, 'syn_overlap_prop':synonyms_overlap_prop,\n",
    "                        'prompt_overlap':prompt_overlap,'prompt_overlap_prop':prompt_overlap_prop},index=[0])\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        source_tokens = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'pos(nouns & verbs)'][essay_set]\n",
    "        source_overlap_temp = [word for word in corrected_tokens if word in source_tokens]\n",
    "        source_overlap = (len(source_overlap_temp))\n",
    "        source_overlap_prop = (len(source_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        synonyms = essay_source_df.loc[essay_source_df['essay_set'] == essay_set,'synonyms'][essay_set]\n",
    "        synonyms_overlap_temp = [word for word in corrected_tokens if word in synonyms]    \n",
    "        synonyms_overlap = (len(synonyms_overlap_temp))\n",
    "        synonyms_overlap_prop = (len(synonyms_overlap_temp)/(len(corrected_tokens)+1))\n",
    "        X = pd.DataFrame({'word_count' : word_count, 'sent_count' : sent_count, 'spell_err' : spell_err,'noun_count': noun_count,\n",
    "                        'verb_count' : verb_count,'adv_count':adv_count, 'adj_count':adj_count, 'readability_score':readability_score, \n",
    "                        'unique_word_ratio':unique_word_ratio,'syn_overlap':synonyms_overlap, 'syn_overlap_prop':synonyms_overlap_prop,\n",
    "                        'source_overlap':source_overlap,'source_overlap_prop':source_overlap_prop},index=[0])\n",
    "    vectorizer = joblib.load('tfidf_set7.pkl')\n",
    "    vectors = vectorizer.transform([essay_documents])\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    dense = vectors.todense()\n",
    "    denselist = dense.tolist() \n",
    "    df = pd.DataFrame(denselist, columns=feature_names)\n",
    "    \n",
    "    final_df = pd.concat([X,df],axis=1)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDsylwXHqrVX"
   },
   "outputs": [],
   "source": [
    "essay = essay_set['essay'][1784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1245,
     "status": "error",
     "timestamp": 1587236574187,
     "user": {
      "displayName": "Prashant Patel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjtTuTn9bJ81oPGEng4pSTboCmiWgsiodWI4sswBw=s64",
      "userId": "11727889337876506696"
     },
     "user_tz": -330
    },
    "id": "4t6j3H2HqtCZ",
    "outputId": "0129cc89-41c3-4a34-aa59-109667e5d9eb"
   },
   "outputs": [],
   "source": [
    "df = create_data(essay,7,essay_prompt_df,essay_source_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>spell_err</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>readability_score</th>\n",
       "      <th>unique_word_ratio</th>\n",
       "      <th>syn_overlap</th>\n",
       "      <th>...</th>\n",
       "      <th>zero</th>\n",
       "      <th>zing</th>\n",
       "      <th>zinged</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipping</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoomed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>167</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 6901 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_count  sent_count  spell_err  noun_count  verb_count  adv_count  \\\n",
       "0         167           3          8          33          16          6   \n",
       "\n",
       "   adj_count  readability_score  unique_word_ratio  syn_overlap   ...    zero  \\\n",
       "0         15               11.6           0.666667           36   ...     0.0   \n",
       "\n",
       "   zing  zinged  zip  zipping  zombie  zone  zoo  zoom  zoomed  \n",
       "0   0.0     0.0  0.0      0.0     0.0   0.0  0.0   0.0     0.0  \n",
       "\n",
       "[1 rows x 6901 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "regresor = joblib.load('model_set2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regressor.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.52269274])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3583    15\n",
       "3584    13\n",
       "3585    15\n",
       "3586    17\n",
       "3587    13\n",
       "3588    23\n",
       "3589    16\n",
       "3590    18\n",
       "3591    12\n",
       "3592    10\n",
       "3593    16\n",
       "3594    19\n",
       "3595    17\n",
       "3596    14\n",
       "3597    12\n",
       "3598    16\n",
       "3599    17\n",
       "3600    16\n",
       "3601    21\n",
       "3602    14\n",
       "3603    18\n",
       "3604    24\n",
       "3605    17\n",
       "3606    16\n",
       "3607    16\n",
       "3608     9\n",
       "3609     6\n",
       "3610    10\n",
       "3611    17\n",
       "3612    16\n",
       "        ..\n",
       "5122    24\n",
       "5123    24\n",
       "5124    14\n",
       "5125    18\n",
       "5126    16\n",
       "5127    16\n",
       "5128    13\n",
       "5129    14\n",
       "5130    14\n",
       "5131    16\n",
       "5132    13\n",
       "5133    15\n",
       "5134    16\n",
       "5135     9\n",
       "5136    15\n",
       "5137    16\n",
       "5138    18\n",
       "5139    18\n",
       "5140     8\n",
       "5141     8\n",
       "5142    19\n",
       "5143    14\n",
       "5144    18\n",
       "5145    19\n",
       "5146    24\n",
       "5147    12\n",
       "5148    16\n",
       "5149    19\n",
       "5150    22\n",
       "5151    15\n",
       "Name: domain1_score, Length: 1569, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AES _2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
